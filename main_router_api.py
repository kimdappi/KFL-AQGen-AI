"""
Agentic RAG ë©”ì¸ íŒŒì¼ - FastAPI ë²„ì „ (ì•ˆì „í•œ ì´ˆê¸°í™” ë²„ì „)

- ì „ì—­ì—ì„œ ë°”ë¡œ Retriever / Graphë¥¼ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.
- init_resources() ì•ˆì—ì„œ í•œ ë²ˆë§Œ lazy ì´ˆê¸°í™”í•˜ê³ ,
  ì—ëŸ¬ê°€ ë‚˜ë©´ ì„œë²„ê°€ ì£½ì§€ ì•Šê³  /generate ìš”ì²­ì—ì„œ 500ìœ¼ë¡œë§Œ ì‘ë‹µí•œë‹¤.
- /generate ì—”ë“œí¬ì¸íŠ¸ëŠ” queryë¥¼ ë°›ì•„ì„œ _run_pipeline_onceë¥¼ ì‹¤í–‰í•˜ê³ ,
  ìƒì„±ëœ ë¬¸ì œë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•œë‹¤.
"""

import json
import uuid
from pathlib import Path
from typing import List, Optional

from dotenv import load_dotenv
from langchain_core.runnables import RunnableConfig

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse ## respone ëª¨ë¸ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë°”ë¡œ í˜¸ì¶œ ì‹œë„
from pydantic import BaseModel

# í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ
from Retriever.vocabulary_retriever import TOPIKVocabularyRetriever
from Retriever.grammar_retriever import GrammarRetriever
from Retriever.kpop_retriever import KpopSentenceRetriever

from Ragsystem.graph_agentic_router import RouterAgenticGraph
from config import TOPIK_PATHS, GRAMMAR_PATHS, KPOP_JSON_PATH
from test_maker import create_korean_test_set

load_dotenv()

# -------------------------------------------------------------------
# FastAPI ê¸°ë³¸ ì„¸íŒ…
# -------------------------------------------------------------------
app = FastAPI(
    title="KFL-AQGen-AI API",
    description="ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìë™ ìƒì„± ì‹œìŠ¤í…œ (FastAPI)",
    version="0.1.0",
)

# CORS: í”„ë¡ íŠ¸(index.html)ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í•„ìš”í•˜ë©´ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ ê°€ëŠ¥
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -------------------------------------------------------------------
# ì…ë ¥/ì¶œë ¥ ëª¨ë¸
# -------------------------------------------------------------------
class QueryRequest(BaseModel):
    query: str


class GenerateResponse(BaseModel):
    query: str
    num_questions: int
    questions: List[dict]


# -------------------------------------------------------------------
# ì „ì—­ ìƒíƒœ (lazy ì´ˆê¸°í™”)
# -------------------------------------------------------------------
topik_retriever: Optional[TOPIKVocabularyRetriever] = None
grammar_retriever: Optional[GrammarRetriever] = None
kpop_retriever: Optional[KpopSentenceRetriever] = None
graph: Optional[RouterAgenticGraph] = None

# ëˆ„ì  ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ + ì¶œë ¥ ê²½ë¡œ
all_generated_questions: list = []
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_PATH = OUTPUT_DIR / "final_v.1.json"


def init_resources():
    """
    Retrieverì™€ Agentic RAG Graphë¥¼ 'í•„ìš”í•  ë•Œ í•œ ë²ˆë§Œ' ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜.
    - ì „ì—­ì—ì„œ ë°”ë¡œ ì´ˆê¸°í™”í•˜ì§€ ì•Šê³ , ìš”ì²­ ì‹œì— í˜¸ì¶œí•´ì„œ ì—ëŸ¬ê°€ ë‚˜ë„ ì„œë²„ê°€ ì£½ì§€ ì•Šë„ë¡ í•œë‹¤.
    """
    global topik_retriever, grammar_retriever, kpop_retriever, graph

    if graph is not None:
        # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ë°”ë¡œ ë¦¬í„´
        return

    print("\n" + "=" * 80)
    print("ğŸš€ ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìë™ ìƒì„± ì‹œìŠ¤í…œ (FastAPI)")
    print("   KFL-AQGen-AI with Intelligent Router")
    print("=" * 80)

    print("\nğŸ“š ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")

    try:
        print("   â”œâ”€ TOPIK ì–´íœ˜ ë°ì´í„°ë² ì´ìŠ¤")
        topik_retriever = TOPIKVocabularyRetriever(TOPIK_PATHS)

        print("   â”œâ”€ ë¬¸ë²• íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤")
        grammar_retriever = GrammarRetriever(GRAMMAR_PATHS)

        print("   â””â”€ K-pop í•™ìŠµ ìë£Œ ë°ì´í„°ë² ì´ìŠ¤")
        kpop_retriever = KpopSentenceRetriever(KPOP_JSON_PATH)

        print("   âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        # ì—¬ê¸°ì„œ ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ í„°ëœ¨ë¦¬ë©´ ì•±ì´ ì£½ìœ¼ë‹ˆ, RuntimeErrorë¡œ ê°ì‹¸ì„œ ìœ„ì—ì„œ 500ìœ¼ë¡œ ì²˜ë¦¬
        print(f"âŒ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise RuntimeError(f"ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨(ë¦¬íŠ¸ë¦¬ë²„): {e}")

    print("\nğŸ”§ ì§€ëŠ¥í˜• ë¼ìš°í„° ê¸°ë°˜ Agentic RAG ê·¸ë˜í”„ êµ¬ì¶• ì¤‘...")
    try:
        graph = RouterAgenticGraph(
            topik_retriever,
            grammar_retriever,
            kpop_retriever,
        )
        print("   âœ… ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ê·¸ë˜í”„ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise RuntimeError(f"ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨(ê·¸ë˜í”„): {e}")

    print("\n" + "=" * 80)
    print("ğŸ¯ Agentic RAG ì‹œìŠ¤í…œ (ì§€ëŠ¥í˜• ë¼ìš°í„°, FastAPI ëª¨ë“œ)")
    print("=" * 80)


def _run_pipeline_once(query: str):
    """
    í•œ ë²ˆì˜ ì¿¼ë¦¬ ì²˜ë¦¬ ë¡œì§.

    - ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” (lazy)
    - ê·¸ë˜í”„ ì‹¤í–‰
    - question_payloadë¡œë¶€í„° ë¬¸ì œ ìƒì„±
    - ì „ì—­ all_generated_questionsì— ëˆ„ì 
    - output/final_v.1.jsonì— ì €ì¥
    - ì´ë²ˆì— ìƒˆë¡œ ìƒì„±ëœ ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    global all_generated_questions

    query = query.strip()
    if not query:
        raise ValueError("ì¿¼ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # 0. ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
    init_resources()

    # ì„¤ì • (ìš”ì²­ë§ˆë‹¤ thread_id ìƒˆë¡œ ë¶€ì—¬)
    config = RunnableConfig(
        recursion_limit=25,
        configurable={"thread_id": str(uuid.uuid4())},
    )

    print(f"\n{'=' * 80}")
    print(f"ğŸ”¹ ì²˜ë¦¬ ì¤‘...")
    print(f"   ì…ë ¥: {query}")
    print("=" * 80)

    # 1. Agentic RAG ì‹¤í–‰
    try:
        graph_result = graph.invoke(query, config)  # type: ignore[arg-type]
        rag_output_string = graph_result.get("final_output", "")
        question_payload = graph_result.get("question_payload")
        print("\n" + "=" * 80)
        print("ğŸ“¤ RAG ìµœì¢… ì¶œë ¥:")
        print(rag_output_string)
        print("=" * 80)
    except Exception as e:
        print(f"âŒ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise RuntimeError(f"ê·¸ë˜í”„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # 2. question_payload í™•ì¸ ë° ì •ë³´ ì¶œë ¥
    if not question_payload:
        print("âŒ question_payloadë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        raise RuntimeError("question_payloadê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("\n" + "=" * 70)
    print("ğŸ“‹ ì¶”ì¶œëœ í•™ìŠµ ìë£Œ ì •ë³´")
    print("=" * 70)
    print(f"   í•™ìŠµì ìˆ˜ì¤€ (ë“±ê¸‰): {question_payload.get('level')}")
    print(f"   ëª©í‘œ ë¬¸ë²•: {question_payload.get('target_grammar')}")

    # critique_summary
    if question_payload.get("critique_summary"):
        print(f"   ìƒì„±ëœ ì˜ˆë¬¸: {len(question_payload.get('critique_summary', []))}ê°œ")
        for i, item in enumerate(question_payload.get("critique_summary", []), 1):
            print(f"      {i}. {item.get('sentence', 'N/A')}")

    # vocabulary
    if question_payload.get("vocabulary"):
        vocab_list = question_payload.get("vocabulary", [])
        vocab_details = question_payload.get("vocabulary_details", [])
        print(f"   ì¶”ì¶œëœ ë‹¨ì–´: {len(vocab_list)}ê°œ")
        if vocab_details:
            for i, v in enumerate(vocab_details, 1):
                print(f"      {i}. {v.get('word', 'N/A')} ({v.get('wordclass', 'N/A')})")
        else:
            for i, v in enumerate(vocab_list, 1):
                print(f"      {i}. {v}")

    # K-pop ì •ë³´ í™•ì¸
    if "kpop_references" in question_payload:
        kpop_refs = question_payload["kpop_references"] or []
        if kpop_refs:
            print(f"\n   âœ¨ K-pop ì°¸ì¡° ìë£Œ: ì´ {len(kpop_refs)}ê°œ")
            for i, ref in enumerate(kpop_refs, 1):
                group = ref.get("group", "N/A")
                song = ref.get("song", "")
                if song:
                    print(f"      {i}. [DB] {group} - {song}")
                else:
                    agency = ref.get("agency", "")
                    fandom = ref.get("fandom", "")
                    members = ref.get("members", [])
                    concepts = ref.get("concepts", [])

                    member_names = [
                        m.get("name", "") if isinstance(m, dict) else m
                        for m in members
                    ]
                    member_names = [n for n in member_names if n]

                    info_parts = []
                    if agency:
                        info_parts.append(f"ì†Œì†ì‚¬: {agency}")
                    if fandom:
                        info_parts.append(f"íŒ¬ë¤: {fandom}")
                    if member_names:
                        info_parts.append(f"ë©¤ë²„: {', '.join(member_names)}")
                    if concepts:
                        info_parts.append(f"ì»¨ì…‰: {', '.join(concepts)}")

                    info_str = " | ".join(info_parts) if info_parts else ""
                    print(f"      {i}. [DB] {group}" + (f" ({info_str})" if info_str else ""))

    print("=" * 70)

    # 3. ë¬¸ì œ ìƒì„±
    print("\nğŸ¯ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    print("   Payload í™•ì¸:")
    print(f"      - level: {question_payload.get('level')}")
    print(f"      - target_grammar: {question_payload.get('target_grammar')}")
    print(f"      - vocabulary: {len(question_payload.get('vocabulary', []))}ê°œ")

    generated_questions = create_korean_test_set(
        question_payload,
        num_questions=6,
    )

    if not generated_questions:
        print("\nâŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨ - ìƒì„±ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ê°€ëŠ¥í•œ ì›ì¸:")
        print("   1. LLM í˜¸ì¶œ ì‹¤íŒ¨")
        print("   2. JSON íŒŒì‹± ì‹¤íŒ¨")
        print("   3. ëª¨ë“  ë¬¸ì œ ìœ í˜•ì—ì„œ ì—ëŸ¬ ë°œìƒ")
        raise RuntimeError("ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")

    print("\n" + "=" * 70)
    print("âœ… ìƒì„±ëœ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ì„¸íŠ¸ (ì´ë²ˆ ìš”ì²­)")
    print("=" * 70)
    print(json.dumps(generated_questions, indent=2, ensure_ascii=False))
    print("=" * 70)

    # 4. ëˆ„ì  + ì €ì¥
    all_generated_questions.extend(generated_questions)
    print(f"\n   ğŸ“Š í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ë¬¸ì œ ìˆ˜: {len(all_generated_questions)}ê°œ")

    print("\n" + "=" * 80)
    print("ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì¤‘...")
    print("=" * 80)
    print(f"   ìƒì„±ëœ ë¬¸ì œ ìˆ˜(ëˆ„ì ): {len(all_generated_questions)}ê°œ")
    print(f"   ì €ì¥ íŒŒì¼ëª…: {OUTPUT_PATH}")

    try:
        with OUTPUT_PATH.open("w", encoding="utf-8") as f:
            json.dump(all_generated_questions, f, ensure_ascii=False, indent=2)
        print(f"   âœ… '{OUTPUT_PATH}' ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"   âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        # ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¬¸ì œ ìƒì„±ì€ ëìœ¼ë‹ˆ, ì—ëŸ¬ë§Œ ì°ê³  ì§„í–‰

    print("\n" + "=" * 80)
    print("ğŸ‰ ì´ë²ˆ ì¿¼ë¦¬ì— ëŒ€í•œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
    print("=" * 80 + "\n")

    return generated_questions

# -------------------------------------------------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# -------------------------------------------------------------------
@app.post("/generate")
async def generate_questions(payload: QueryRequest):
    """
    HTMLì—ì„œ ì¿¼ë¦¬ë¥¼ ë°›ì•„ì„œ:
      1) ë‚´ë¶€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
      2) output/final_v.1.jsonì— ëˆ„ì  ì €ì¥
      3) ìƒì„±ëœ ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ JSONìœ¼ë¡œ ë°˜í™˜
    """
    query = payload.query.strip()
    if not query:
        raise HTTPException(status_code=400, detail="queryê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        questions = _run_pipeline_once(query)
    except Exception as e:
        # í„°ë¯¸ë„ì—ì„œë„ í™•ì¸í•˜ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì„œ print(e) í•œ ë²ˆ ë” ê°€ëŠ¥
        raise HTTPException(status_code=500, detail=str(e))

    # â˜… Pydantic ëª¨ë¸ ì•ˆ ê±°ì¹˜ê³ , ê·¸ëƒ¥ ìˆœìˆ˜ JSONìœ¼ë¡œ ì‘ë‹µ
    return JSONResponse(
        content={
            "query": query,
            "num_questions": len(questions),
            "questions": questions,
        },
    )



@app.get("/health")
async def health_check():
    """
    ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸.
    - /docsê°€ ë–  ìˆëŠ”ì§€ í™•ì¸ + ì„œë²„ ì‚´ì•„ìˆëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸ìš©.
    """
    return {"status": "ok"}

"""
python -m uvicorn main_router_api:app --reload
"""