"""
Agentic RAG ë©”ì¸ íŒŒì¼
"""

import json
import uuid
from dotenv import load_dotenv
from langchain_core.runnables import RunnableConfig
# 
from Retriever.vocabulary_retriever import TOPIKVocabularyRetriever
from Retriever.grammar_retriever import GrammarRetriever
from Retriever.kpop_retriever import KpopSentenceRetriever

from Ragsystem.graph_agentic_router import RouterAgenticGraph
from config import TOPIK_PATHS, GRAMMAR_PATHS, KPOP_JSON_PATH
from test_maker import create_korean_test_set

load_dotenv()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë¼ìš°í„° í†µí•© ë²„ì „)"""
    
    print("\n" + "="*80)
    print("ğŸš€ ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìë™ ìƒì„± ì‹œìŠ¤í…œ")
    print("   KFL-AQGen-AI with Intelligent Router")
    print("="*80)
    
    # ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
    print("\nğŸ“š ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    print("   â”œâ”€ TOPIK ì–´íœ˜ ë°ì´í„°ë² ì´ìŠ¤")
    topik_retriever = TOPIKVocabularyRetriever(TOPIK_PATHS)
    print("   â”œâ”€ ë¬¸ë²• íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤")
    grammar_retriever = GrammarRetriever(GRAMMAR_PATHS)
    print("   â””â”€ K-pop í•™ìŠµ ìë£Œ ë°ì´í„°ë² ì´ìŠ¤")
    kpop_retriever = KpopSentenceRetriever(KPOP_JSON_PATH)
    print("   âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ë¼ìš°í„° í†µí•© Agentic RAG ê·¸ë˜í”„ êµ¬ì¶•
    print("\nğŸ”§ ì§€ëŠ¥í˜• ë¼ìš°í„° ê¸°ë°˜ Agentic RAG ê·¸ë˜í”„ êµ¬ì¶• ì¤‘...")
    graph = RouterAgenticGraph(
        topik_retriever,
        grammar_retriever,
        kpop_retriever
    )
    print("   âœ… ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ")
    
    # ì„¤ì •
    config = RunnableConfig(
        recursion_limit=25,  # ì¬ê²€ìƒ‰ì„ ìœ„í•´ ì•½ê°„ ì¦ê°€
        configurable={"thread_id": str(uuid.uuid4())}
    )
    
    print("\n" + "="*80)
    print("ğŸ¯ Agentic RAG ì‹œìŠ¤í…œ ì‹œì‘ (ì§€ëŠ¥í˜• ë¼ìš°í„°)")
    print("="*80)
    
    all_generated_questions = []
    
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("\nğŸ’¬ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œë¥¼ ìƒì„±í•  ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("   ì˜ˆì‹œ: 'Create intermediate level Korean grammar practice questions about BLACKPINK'")
    print("   ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    while True:
        query = input("ğŸ“ ì¿¼ë¦¬ ì…ë ¥: ").strip()
        
        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'ê·¸ë§Œ']:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not query:
            print("   âš ï¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
            continue
        
        print(f"\n{'='*80}")
        print(f"ğŸ”¹ ì²˜ë¦¬ ì¤‘...")
        print(f"   ì…ë ¥: {query}")
        print('='*80)

        # 1. ë¼ìš°í„° ê¸°ë°˜ Agentic RAG ì‹¤í–‰
        try:
            graph_result = graph.invoke(query, config)
            rag_output_string = graph_result.get('final_output', '')
            question_payload = graph_result.get('question_payload')
            print("\n" + "="*80)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            continue

        # 2. question_payload í™•ì¸ ë° ì •ë³´ ì¶œë ¥
        if not question_payload:
            print("âŒ question_payloadë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        print("\n" + "="*70)
        print("ğŸ“‹ ì¶”ì¶œëœ í•™ìŠµ ìë£Œ ì •ë³´")
        print("="*70)
        print(f"   í•™ìŠµì ìˆ˜ì¤€ (ë“±ê¸‰): {question_payload.get('level')}")
        print(f"   ëª©í‘œ ë¬¸ë²•: {question_payload.get('target_grammar')}")
        
        # ê¸°ì¡´ í˜•ì‹ í˜¸í™˜ì„± ì²´í¬ (critique_summaryê°€ ìˆìœ¼ë©´ í‘œì‹œ)
        if 'critique_summary' in question_payload and question_payload.get('critique_summary'):
            print(f"   ìƒì„±ëœ ì˜ˆë¬¸: {len(question_payload.get('critique_summary', []))}ê°œ")
            for i, item in enumerate(question_payload.get('critique_summary', []), 1):
                print(f"      {i}. {item.get('sentence', 'N/A')}")
        # ìƒˆë¡œìš´ í˜•ì‹ (ì •ë³´ë§Œ ì¶”ì¶œ)
        if 'vocabulary' in question_payload and question_payload.get('vocabulary'):
            vocab_list = question_payload.get('vocabulary', [])
            vocab_details = question_payload.get('vocabulary_details', [])
            print(f"   ì¶”ì¶œëœ ë‹¨ì–´: {len(vocab_list)}ê°œ")
            if vocab_details:
                # ëª¨ë“  ë‹¨ì–´ ì¶œë ¥ (5ê°œ)
                for i, v in enumerate(vocab_details, 1):
                    print(f"      {i}. {v.get('word', 'N/A')} ({v.get('wordclass', 'N/A')})")
            elif vocab_list:
                # ëª¨ë“  ë‹¨ì–´ ì¶œë ¥ (5ê°œ)
                for i, v in enumerate(vocab_list, 1):
                    print(f"      {i}. {v}")
        
        # K-pop ì •ë³´ í™•ì¸
        if 'kpop_references' in question_payload:
            kpop_refs = question_payload['kpop_references']
            
            if kpop_refs:
                print(f"\n   âœ¨ K-pop ì°¸ì¡° ìë£Œ: ì´ {len(kpop_refs)}ê°œ")
                
                for i, ref in enumerate(kpop_refs, 1):
                    group = ref.get('group', 'N/A')
                    song = ref.get('song', '')
                    if song:
                        print(f"      {i}. [DB] {group} - {song}")
                    else:
                        # ìƒˆë¡œìš´ í˜•ì‹ - ëª¨ë“  ì •ë³´ í‘œì‹œ
                        agency = ref.get('agency', '')
                        fandom = ref.get('fandom', '')
                        members = ref.get('members', [])
                        concepts = ref.get('concepts', [])
                        
                        # ëª¨ë“  ë©¤ë²„ ì´ë¦„ ì¶”ì¶œ
                        member_names = [m.get('name', '') if isinstance(m, dict) else m for m in members]
                        member_names = [n for n in member_names if n]  # ë¹ˆ ë¬¸ìì—´ ì œê±°
                        
                        # ì •ë³´ êµ¬ì„±
                        info_parts = []
                        if agency:
                            info_parts.append(f"ì†Œì†ì‚¬: {agency}")
                        if fandom:
                            info_parts.append(f"íŒ¬ë¤: {fandom}")
                        if member_names:
                            info_parts.append(f"ë©¤ë²„: {', '.join(member_names)}")
                        if concepts:
                            info_parts.append(f"ì»¨ì…‰: {', '.join(concepts)}")
                        
                        info_str = " | ".join(info_parts) if info_parts else ""
                        print(f"      {i}. [DB] {group}" + (f" ({info_str})" if info_str else ""))
        
        print("="*70)
        
        # 3. ë¬¸ì œ ìƒì„±
        print("\nğŸ¯ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
        print(f"   Payload í™•ì¸:")
        print(f"      - level: {question_payload.get('level')}")
        print(f"      - target_grammar: {question_payload.get('target_grammar')}")
        print(f"      - vocabulary: {len(question_payload.get('vocabulary', []))}ê°œ")
        
        generated_questions = create_korean_test_set(question_payload, num_questions=6)

        if generated_questions:
            print("\n" + "="*70)
            print("âœ… ìƒì„±ëœ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ì„¸íŠ¸")
            print("="*70)
            print(json.dumps(generated_questions, indent=2, ensure_ascii=False))
            print("="*70)

            all_generated_questions.extend(generated_questions)
            print(f"\n   ğŸ“Š í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ë¬¸ì œ ìˆ˜: {len(all_generated_questions)}ê°œ")
        else:
            print("\nâŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨ - ìƒì„±ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("   ê°€ëŠ¥í•œ ì›ì¸:")
            print("   1. LLM í˜¸ì¶œ ì‹¤íŒ¨")
            print("   2. JSON íŒŒì‹± ì‹¤íŒ¨")
            print("   3. ëª¨ë“  ë¬¸ì œ ìœ í˜•ì—ì„œ ì—ëŸ¬ ë°œìƒ")
            print("   ìœ„ì˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


        print("\n" + "="*80)
    
    # ìµœì¢… ì¶œë ¥ ì €ì¥
    output_filename = "output/final_v.1.json"
    print(f"\n{'='*80}")
    print(f"ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì¤‘...")
    print(f"{'='*80}")
    print(f"   ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {len(all_generated_questions)}ê°œ")
    print(f"   ì €ì¥ íŒŒì¼ëª…: {output_filename}")

    try:
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(all_generated_questions, f, ensure_ascii=False, indent=2)
        print(f"   âœ… '{output_filename}' ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"   âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    print("\n" + "="*80)
    print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("   ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()