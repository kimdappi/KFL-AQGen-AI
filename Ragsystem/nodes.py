"""
LangGraph ë…¸ë“œ ì •ì˜ (ê°œì„ ëœ ì¬ìƒì„± ë¡œì§ - ê°„ê²° ë²„ì „)
"""
from typing import List, Dict, Any

from langchain.chat_models import ChatOpenAI
from Ragsystem.schema import GraphState
from utils import (
    extract_words_from_docs,
    extract_grammar_with_grade,
    get_group_type,
)
from config import LLM_CONFIG
from agents import QueryAnalysisAgent, QualityCheckAgent


#ê¸°ë³¸ RAG ë…¸ë“œ
class KoreanLearningNodes:
    """í•œêµ­ì–´ í•™ìŠµ ë…¸ë“œ í´ë˜ìŠ¤"""

    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        self.vocabulary_retriever = vocabulary_retriever
        self.grammar_retriever = grammar_retriever
        self.kpop_retriever = kpop_retriever
        self.llm = llm or ChatOpenAI(
            model="gpt-5",
            temperature=LLM_CONFIG.get("temperature", 0.7),
            max_completion_tokens=LLM_CONFIG.get("max_completion_tokens", 1000),
        )

    def retrieve_vocabulary(self, state: GraphState) -> GraphState:
        """ë‹¨ì–´ ê²€ìƒ‰ ë…¸ë“œ"""
        level = state["difficulty_level"]
        query = state["input_text"]
        vocab_docs = self.vocabulary_retriever.invoke(query, level)
        return {"vocabulary_docs": vocab_docs}

    def retrieve_grammar(self, state: GraphState) -> GraphState:
        """ë¬¸ë²• ê²€ìƒ‰ ë…¸ë“œ"""
        level = state["difficulty_level"]
        query = state["input_text"]
        grammar_docs = self.grammar_retriever.invoke(query, level)
        return {"grammar_docs": grammar_docs}



#Agentic RAG ë…¸ë“œ - ì¿¼ë¦¬ ë¶„ì„
class AgenticKoreanLearningNodes(KoreanLearningNodes):
    """Agentic RAG ë…¸ë“œ - ë¦¬íŠ¸ë¦¬ë²„ ì •ë³´ ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ 3ë¬¸ì¥ ìƒì„± (ê°„ê²° ë²„ì „)"""

    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        super().__init__(vocabulary_retriever, grammar_retriever, kpop_retriever, llm)
        # kpop_retrieverë¥¼ QueryAnalysisAgentì— ì „ë‹¬í•˜ì—¬ ì„ë² ë”© ê¸°ë°˜ ë§¤ì¹­ í™œì„±í™”
        self.query_agent = QueryAnalysisAgent(llm, kpop_retriever=kpop_retriever)
        self.quality_agent = QualityCheckAgent(llm)

    #Agents Nodes 

    def analyze_query_agent(self, state: GraphState) -> GraphState:
        """ì¿¼ë¦¬ ë¶„ì„ ì—ì´ì „íŠ¸ ë…¸ë“œ"""
        print("\nğŸ” [Agent] Query Analysis")
        analysis = self.query_agent.analyze(state["input_text"])

        print(f"   Difficulty: {analysis['difficulty']}")
        print(f"   Topic: {analysis['topic']}")
        print(f"   Needs K-pop: {analysis.get('needs_kpop', False)}")
        kpop_filters = analysis.get('kpop_filters', {})
        if kpop_filters:
            filter_info = []
            if kpop_filters.get('groups'):
                filter_info.append(f"ê·¸ë£¹: {kpop_filters['groups']}")
            if kpop_filters.get('members'):
                filter_info.append(f"ë©¤ë²„: {kpop_filters['members']}")
            if kpop_filters.get('agencies'):
                filter_info.append(f"ì†Œì†ì‚¬: {kpop_filters['agencies']}")
            if kpop_filters.get('fandoms'):
                filter_info.append(f"íŒ¬ë¤: {kpop_filters['fandoms']}")
            if kpop_filters.get('concepts'):
                filter_info.append(f"ì»¨ì…‰: {kpop_filters['concepts']}")
            if kpop_filters.get('debut_year'):
                filter_info.append(f"ë°ë·”: {kpop_filters['debut_year']}ë…„")
            if kpop_filters.get('group_type'):
                filter_info.append(f"íƒ€ì…: {kpop_filters['group_type']}")
            if filter_info:
                print(f"   K-pop í•„í„°: {', '.join(filter_info)}")

        return {
            "difficulty_level": analysis["difficulty"],
            "query_analysis": analysis,
        }

    def check_quality_agent(self, state: GraphState) -> GraphState:
        """í’ˆì§ˆ ê²€ì¦ ì—ì´ì „íŠ¸ ë…¸ë“œ (ë¦¬ì†ŒìŠ¤ ì¶©ë¶„í•œì§€ë§Œ í™•ì¸)"""
        print("\nâœ… [Agent] í’ˆì§ˆ ê²€ì¦")

        query_analysis = state.get("query_analysis", {})
        needs_kpop = query_analysis.get("needs_kpop", False)

        result = self.quality_agent.check(
            vocab_count=len(state.get("vocabulary_docs", [])),
            grammar_count=len(state.get("grammar_docs", [])),
            kpop_db_count=len(state.get("kpop_docs", [])),
            needs_kpop=needs_kpop,
        )

        print(f"   ì–´íœ˜: {result['vocab_count']}ê°œ")
        print(f"   ë¬¸ë²•: {result['grammar_count']}ê°œ")
        print(f"   K-pop: {result['kpop_db_count']}ê°œ")
        print(f"   ìƒíƒœ: {result['message']}")

        return {"quality_check": result}

    def _process_kpop_docs_enhanced(
        self,
        kpop_docs,
    ):
        """
        K-pop ë¬¸ì„œì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        ì£¼ì˜: í•„í„°ë§ì€ ì´ë¯¸ retrieve_kpop_routedì—ì„œ ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ê³¼ ë©”íƒ€ë°ì´í„° í•„í„°ë§ìœ¼ë¡œ ì™„ë£Œë¨
        ì´ í•¨ìˆ˜ëŠ” ë‹¨ìˆœíˆ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ë§Œ ìˆ˜í–‰
        """
        kpop_metadata: List[Dict[str, Any]] = []

        if not kpop_docs:
            return kpop_metadata

        # ì´ë¯¸ í•„í„°ë§ëœ ë¬¸ì„œë“¤ì—ì„œ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ (ìµœëŒ€ 5ê°œ)
        for doc in kpop_docs[:5]:
            meta = doc.metadata
            group = meta.get("group", "")
            if not group:
                continue

            # ì „ì²´ ê·¸ë£¹ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥ (ëª¨ë“  ì •ë³´ í¬í•¨)
            full_meta = {
                "group": group,
                "agency": meta.get("agency", ""),
                "fandom": meta.get("fandom", ""),
                "concepts": meta.get("concepts", []),
                "members": [
                    {
                        "name": m.get("name", ""),
                        "role": m.get("role", ""),
                    }
                    for m in meta.get("members", [])  # ëª¨ë“  ë©¤ë²„ í¬í•¨
                ],
            }
            kpop_metadata.append(full_meta)

        return kpop_metadata

    def generate_question_directly(self, state: GraphState) -> GraphState:
        """
        ë¬¸ì¥ ìƒì„± ì—†ì´ ì¶”ì¶œëœ ì •ë³´ë¡œ ë°”ë¡œ ë¬¸ì œ ìƒì„±ìš© payload êµ¬ì„±
        - ë‹¨ì–´ 5ê°œ ì¶”ì¶œ (ë‚œì´ë„ì— ë§ëŠ” ê²ƒ) - ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì œ ìƒì„±ì„ ìœ„í•´ ì¦ê°€
        - ë¬¸ë²• 1ê°œ ì¶”ì¶œ (ë‚œì´ë„ì— ë§ëŠ” ê²ƒ)
        - K-pop ì •ë³´ ìµœëŒ€ 5ê°œ ì¶”ì¶œ (ì¿¼ë¦¬ì— K-pop ê´€ë ¨ì´ ìˆì„ ë•Œë§Œ) - ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
        """
        print("\nğŸ¯ [Agent] ì •ë³´ ì¶”ì¶œ ë° ë¬¸ì œ ìƒì„±ìš© payload êµ¬ì„±")

        # 1) ë‹¨ì–´ ì¶”ì¶œ (ë‚œì´ë„ì— ë§ëŠ” ê²ƒ, ìµœëŒ€ 5ê°œ)
        words_info = extract_words_from_docs(state.get("vocabulary_docs", []))
        vocab_list = [word for word, _ in words_info][:5]
        vocab_details = []
        for word, wordclass in words_info[:5]:
            vocab_details.append({
                "word": word,
                "wordclass": wordclass
            })
        
        print(f"   âœ… ë‹¨ì–´ ì¶”ì¶œ: {len(vocab_list)}ê°œ - {vocab_list}")

        # 2) ë¬¸ë²• ì¶”ì¶œ (ë‚œì´ë„ì— ë§ëŠ” ê²ƒ, 1ê°œ)
        grammar_info = extract_grammar_with_grade(state.get("grammar_docs", []))
        target_grammar = grammar_info[0]["grammar"] if grammar_info else "ê¸°ë³¸ ë¬¸ë²•"
        target_grade = grammar_info[0]["grade"] if grammar_info else 1
        
        print(f"   âœ… ë¬¸ë²• ì¶”ì¶œ: {target_grammar} (Grade {target_grade})")

        # 3) K-pop ì •ë³´ ì¶”ì¶œ (ìµœëŒ€ 5ê°œ) - ë™ì  í•„í„°ë§
        query_analysis = state.get("query_analysis", {})
        needs_kpop = query_analysis.get("needs_kpop", False)
        kpop_metadata = []
        
        if needs_kpop and state.get("kpop_docs"):
            # í•„í„°ë§ì€ ì´ë¯¸ retrieve_kpop_routedì—ì„œ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ
            kpop_metadata = self._process_kpop_docs_enhanced(
                state.get("kpop_docs", []),
            )
            kpop_metadata = kpop_metadata[:5]  # ìµœëŒ€ 5ê°œë¡œ ì¦ê°€
            
            # ì‹¤ì œ ì¶”ì¶œëœ ì •ë³´ í™•ì¸
            extracted_groups = set([m.get("group", "") for m in kpop_metadata])
            if extracted_groups:
                print(f"   âœ… K-pop ì •ë³´ ì¶”ì¶œ: {len(kpop_metadata)}ê°œ")
                print(f"   ğŸ“‹ ì¶”ì¶œëœ ê·¸ë£¹: {list(extracted_groups)}")
            else:
                print(f"   âœ… K-pop ì •ë³´ ì¶”ì¶œ: {len(kpop_metadata)}ê°œ")
        else:
            print(f"   â­ï¸  K-pop ì •ë³´ ì—†ìŒ (ì¿¼ë¦¬ì— K-pop ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ)")

        # ë‚œì´ë„ ë§¤í•‘ (TOPIK ë ˆë²¨ â†’ ì‹œìŠ¤í…œ ë‚œì´ë„)
        difficulty = state["difficulty_level"]
        level_mapping = {
            "basic": "grade1-2",
            "intermediate": "grade3-4",
            "advanced": "grade5-6"
        }
        level = level_mapping.get(difficulty, f"grade{target_grade}")

        # ë¬¸ì œ ìƒì„±ìš© ë„˜ê²¨ì¤„ ì •ë³´ êµ¬ì„±
        question_payload = {
            "level": level,
            "target_grammar": target_grammar,
            "vocabulary": vocab_list,
            "vocabulary_details": vocab_details,
            "difficulty": difficulty,
            "grade": target_grade,
        }

        # K-pop ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if kpop_metadata:
            question_payload["kpop_references"] = kpop_metadata



        print(f"   âœ… Payload êµ¬ì„± ì™„ë£Œ")
        print(f"      - Level: {level}")
        print(f"      - Grammar: {target_grammar}")
        print(f"      - Vocabulary: {len(vocab_list)}ê°œ")
        print(f"      - K-pop: {len(kpop_metadata)}ê°œ")

        return {
            "question_payload": question_payload,
            "target_grade": target_grade,
        }

    def format_output_agentic(self, state: GraphState) -> GraphState:
        """Agentic RAG ì¶œë ¥ í¬ë§·íŒ…"""
        print("\nğŸ“„ [Agent] ìµœì¢… ì¶œë ¥")

        output = "=" * 80 + "\n"
        output += "ğŸ“ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± (Agentic RAG)\n"
        output += "=" * 80 + "\n\n"

        # ì¶”ì¶œëœ ì •ë³´ ì¶œë ¥
        if "question_payload" in state:
            question_payload = state.get("question_payload", {})
            output += "ã€ì¶”ì¶œëœ í•™ìŠµ ì •ë³´ã€‘\n"
            output += f"   ëª©í‘œ ë¬¸ë²•: {question_payload.get('target_grammar', 'N/A')}\n"
            vocab_list = question_payload.get("vocabulary", [])
            if vocab_list:
                output += f"   í•™ìŠµ ë‹¨ì–´: {', '.join(vocab_list)}\n"
            kpop_refs = question_payload.get("kpop_references", [])
            if kpop_refs:
                output += f"   K-pop ì°¸ì¡°: {len(kpop_refs)}ê°œ\n"

        output += "\n" + "=" * 80 + "\n"

        return {"final_output": output}