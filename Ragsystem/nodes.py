"""
LangGraph ë…¸ë“œ ì •ì˜ (ê°œì„ ëœ ì¬ìƒì„± ë¡œì§)
"""
import json
import os
import re
import random
from typing import List, Dict, Any
from pathlib import Path
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from Ragsystem.schema import GraphState
from utils import (
    detect_difficulty_from_text,
    extract_words_from_docs,
    extract_grammar_with_grade  
)
from config import LLM_CONFIG, SENTENCE_SAVE_DIR
from agents import QueryAnalysisAgent, QualityCheckAgent

# Evaluator ì„í¬íŠ¸
try:
    from Evaluator.kpop_evaluator import KpopSentenceEvaluator
    EVALUATOR_ENABLED = True
except ImportError:
    EVALUATOR_ENABLED = False
    print("âš ï¸ Evaluator ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")

INVALID_CHARS = r'[<>:"/\\|?*\x00-\x1F]'

def sanitize_filename(name: str, replacement: str = "_") -> str:
    """Windows íŒŒì¼ëª… ì•ˆì „ ì²˜ë¦¬"""
    safe = re.sub(INVALID_CHARS, replacement, name)
    safe = safe.strip().strip(".")
    RESERVED = {"CON","PRN","AUX","NUL",*(f"COM{i}" for i in range(1,10)),*(f"LPT{i}" for i in range(1,10))}
    if safe.upper() in RESERVED:
        safe = f"_{safe}"
    return safe[:120] if len(safe) > 120 else safe

class KoreanLearningNodes:
    """í•œêµ­ì–´ í•™ìŠµ ë…¸ë“œ í´ë˜ìŠ¤"""
    
    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        self.vocabulary_retriever = vocabulary_retriever
        self.grammar_retriever = grammar_retriever
        self.kpop_retriever = kpop_retriever
        self.llm = llm or ChatOpenAI(
            model="gpt-4o-mini",
            temperature=LLM_CONFIG.get('temperature', 0.7),
            max_tokens=LLM_CONFIG.get('max_tokens', 1000)
        )
        
        # Evaluator ì´ˆê¸°í™”
        self.evaluator = None
        if EVALUATOR_ENABLED:
            try:
                self.evaluator = KpopSentenceEvaluator()
                print("   âœ… ë¬¸ì¥ í‰ê°€ê¸° í™œì„±í™”")
            except Exception as e:
                print(f"   â„¹ï¸ í‰ê°€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.evaluator = None
        
        self.output_dir = "sentence"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def detect_difficulty(self, state: GraphState) -> GraphState:
        """ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ë‚œì´ë„ ê°ì§€"""
        difficulty = detect_difficulty_from_text(state['input_text'])
        return {"difficulty_level": difficulty}
    
    def retrieve_vocabulary(self, state: GraphState) -> GraphState:
        """ë‹¨ì–´ ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']
        vocab_docs = self.vocabulary_retriever.invoke(query, level)
        return {"vocabulary_docs": vocab_docs}

    def retrieve_kpop(self, state: GraphState) -> GraphState:
        """K-pop ë¬¸ì¥ ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']
        kpop_docs = self.kpop_retriever.invoke(query, level)
        return {"kpop_docs": kpop_docs}
    
    def retrieve_grammar(self, state: GraphState) -> GraphState:
        """ë¬¸ë²• ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']
        grammar_docs = self.grammar_retriever.invoke(query, level)
        return {"grammar_docs": grammar_docs}

    def generate_sentences(self, state: GraphState) -> GraphState:
        """ê²€ìƒ‰ëœ ë‹¨ì–´ì™€ ë¬¸ë²•ì„ í™œìš©í•œ ë¬¸ì¥ ìƒì„± (K-pop ì •ë³´ í¬í•¨)"""
        words_info = extract_words_from_docs(state['vocabulary_docs'])
        
        # K-pop ì •ë³´ ì¶”ì¶œ
        kpop_references = []
        kpop_context_text = ""
        
        if 'kpop_docs' in state and state['kpop_docs']:
            print(f"[ì°¸ì¡°] K-pop ë¬¸ì„œ ê°œìˆ˜: {len(state['kpop_docs'])}")
            
            for doc in state['kpop_docs'][:3]:
                sentence = doc.metadata.get('sentence', '')
                song = doc.metadata.get('song', '')
                group = doc.metadata.get('group', '')
                
                if sentence:
                    kpop_references.append({
                        "sentence": sentence,
                        "song": song,
                        "group": group,
                    })
                    kpop_context_text += f'- "{sentence}" ({song} - {group})\n'
        
        print(f"[ì°¸ì¡°] K-pop ì°¸ì¡° ê°œìˆ˜: {len(kpop_references)}")
        
        grammar_info = extract_grammar_with_grade(state['grammar_docs'])
        
        # ì–´íœ˜ í¬ë§·íŒ…
        words_formatted = []
        vocab_list = []
        for word, wordclass in words_info[:5]:
            words_formatted.append(f"{word}({wordclass})")
            vocab_list.append(word)
        
        target_grammar = grammar_info[0]['grammar'] if grammar_info else "ê¸°ë³¸ ë¬¸ë²•"
        target_grade = grammar_info[0]['grade'] if grammar_info else 1
        
        print("grammar : ", target_grammar)
        print("grade : ", target_grade)
        
        difficulty = state['difficulty_level']
        difficulty_guide = {
            "basic": "ì´ˆê¸‰ í•™ìŠµì (TOPIK 1-2ê¸‰): ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥, ê¸°ë³¸ ì‹œì œ ì‚¬ìš©",
            "intermediate": "ì¤‘ê¸‰ í•™ìŠµì (TOPIK 3-4ê¸‰): ë‹¤ì–‘í•œ ì—°ê²°ì–´ë¯¸, ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™” í‘œí˜„",
            "advanced": "ê³ ê¸‰ í•™ìŠµì (TOPIK 5-6ê¸‰): ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°, ê²©ì‹ì²´ë‚˜ ë¬¸ì–´ì²´ ê°€ëŠ¥"
        }
        
        # ê° ë¬¸ì¥ì— ì„œë¡œ ë‹¤ë¥¸ ì–´íœ˜ë¥¼ ê°•ì œí• ë‹¹ (ìµœëŒ€ 3ê°œ ì‚¬ìš©)
        selected_words = vocab_list[:3]

        # K-pop ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìƒìœ„ 5ê°œì—ì„œ 3ê°œë¥¼ ê³ ìœ í•˜ê²Œ ì„ íƒí•˜ì—¬ ë¬¸ì¥ë³„ ê°•ì œ í• ë‹¹
        assigned_kpop = []  # [{group, song, members[], concepts[]}]
        if 'kpop_docs' in state and state['kpop_docs']:
            pool = state['kpop_docs'][:5]
            seen = set()
            for d in pool:
                group = (d.metadata.get('group', '') or '').strip()
                song = (d.metadata.get('song', '') or '').strip()
                members = [m.get('name', '').strip() for m in (d.metadata.get('members', []) or []) if m.get('name')]
                concepts = [c.strip() for c in (d.metadata.get('concepts', []) or []) if isinstance(c, str) and c.strip()]
                key = group.lower() if group else (song.lower() if song else None)
                if not key:
                    continue
                if key in seen:
                    continue
                seen.add(key)
                assigned_kpop.append({
                    "group": group,
                    "song": song,
                    "members": members[:3],
                    "concepts": concepts[:3]
                })
                if len(assigned_kpop) >= 3:
                    break

        prompt = self._build_generation_prompt(
            difficulty,
            target_grade,
            words_formatted,
            target_grammar,
            kpop_context_text,
            difficulty_guide,
            selected_words,
            vocab_list,
            assigned_kpop
        )

        # ë¬¸ì¥ ìƒì„± (ê²€ì¦ í¬í•¨, ìµœëŒ€ 2íšŒ ì¬ì‹œë„)
        max_attempts = 2
        sentences = []
        for attempt in range(max_attempts):
            response = self.llm.predict(prompt)
            candidates = response.strip().split('\n')
            candidates = [s.strip() for s in candidates if s.strip()][:3]

            # 3ë¬¸ì¥ í™•ë³´ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            if len(candidates) < 3:
                continue

            # ì–´íœ˜ ê°•ì œ ì‚¬ìš© ê²€ì¦: ë¬¸ì¥1â†’selected_words[0], ë¬¸ì¥2â†’...[1], ë¬¸ì¥3â†’...[2]
            ok = True
            for idx, word in enumerate(selected_words):
                if idx >= 3:
                    break
                if word.lower() not in candidates[idx].lower():
                    ok = False
                    break

            # K-pop ì»¨í…ìŠ¤íŠ¸ ê°•ì œ ê²€ì¦ (ìˆì„ ë•Œë§Œ): ë¬¸ì¥1â†’ctx1, ë¬¸ì¥2â†’ctx2, ë¬¸ì¥3â†’ctx3
            if ok and assigned_kpop:
                for idx, ctx in enumerate(assigned_kpop):
                    if idx >= 3:
                        break
                    group = (ctx.get('group') or '').lower()
                    song = (ctx.get('song') or '').lower()
                    members = [(m or '').lower() for m in (ctx.get('members') or [])]
                    concepts = [(c or '').lower() for c in (ctx.get('concepts') or [])]
                    sent_lower = candidates[idx].lower()
                    included = False
                    if group and group in sent_lower:
                        included = True
                    if not included and song and song in sent_lower:
                        included = True
                    if not included and any(m and m in sent_lower for m in members):
                        included = True
                    if not included and any(c and c in sent_lower for c in concepts):
                        included = True
                    if not included:
                        ok = False
                        break

            if ok:
                sentences = candidates
                break

            # ì‹¤íŒ¨ ì‹œ í”„ë¡¬í”„íŠ¸ë¥¼ ë” ê°•í•˜ê²Œ ë³´ê°•í•˜ì—¬ ì¬ì‹œë„
            missing_idx = idx + 1
            strengthen_note = f"\n[ê°•ì œ ê·œì¹™ ì¬í™•ì¸] ë¬¸ì¥{missing_idx}ì— ë°˜ë“œì‹œ '{selected_words[idx]}'ë¥¼ í¬í•¨í•˜ì„¸ìš”."
            if assigned_kpop and idx < len(assigned_kpop):
                g = assigned_kpop[idx].get('group')
                s = assigned_kpop[idx].get('song')
                ms = assigned_kpop[idx].get('members') or []
                cs = assigned_kpop[idx].get('concepts') or []
                options = []
                if g:
                    options.append(f"ê·¸ë£¹ '{g}'")
                if s:
                    options.append(f"ê³¡ëª… '{s}'")
                if ms:
                    options.append("ë©¤ë²„ " + ", ".join([f"'{m}'" for m in ms]))
                if cs:
                    options.append("ì»¨ì…‰ " + ", ".join([f"'{c}'" for c in cs]))
                if options:
                    strengthen_note += f" ë˜í•œ ë¬¸ì¥{missing_idx}ì— K-pop ê´€ë ¨ ìš”ì†Œ ({' ë˜ëŠ” '.join(options)}) ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
            prompt = prompt + strengthen_note

        # ë§ˆì§€ë§‰ ì‹œë„ê¹Œì§€ ì‹¤íŒ¨í•œ ê²½ìš°ë¼ë„ ìµœì‹  candidates ì‚¬ìš©
        if not sentences:
            sentences = candidates if 'candidates' in locals() else []
        
        # í‰ê°€ ìˆ˜í–‰
        critique_summary = self._evaluate_sentences(
            sentences, 
            target_grammar, 
            vocab_list
        )
        
        # JSON ì €ì¥ ë°ì´í„°
        save_data = {
            "level": target_grade,
            "target_grammar": target_grammar,
            "kpop_references": kpop_references,
            "critique_summary": critique_summary
        }
        
        messages = [
            ("user", state['input_text']),
            ("assistant", "\n".join(sentences))
        ]
        
        return {
            "generated_sentences": sentences,
            "messages": messages,
            "sentence_data": save_data,
            "target_grade": target_grade
        }
    
    def _build_generation_prompt(self, difficulty, target_grade, words_formatted,
                                target_grammar, kpop_context_text, difficulty_guide,
                                selected_words=None, vocab_raw=None, assigned_kpop=None):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        prompt_templates = {
            "basic": """
[ROLE]
ë„ˆëŠ” í•œêµ­ì–´ë¥¼ ë°°ìš°ëŠ” ì´ˆê¸‰ í•™ìŠµìë¥¼ ìœ„í•œ ì¹œì ˆí•œ í•œêµ­ì–´ ì„ ìƒë‹˜ì´ì•¼.

[INSTRUCTIONS]
- í•™ìŠµ ìˆ˜ì¤€: {difficulty_level} (Grade {target_grade})
- ì˜¤ëŠ˜ì˜ ë‹¨ì–´: {words_formatted}
- ì˜¤ëŠ˜ì˜ ë¬¸ë²•: {target_grammar}
- K-pop ì°¸ê³ : {kpop_context_text}

[SENTENCE RULES]
1. ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥ (10-15 ë‹¨ì–´)
2. ë¬¸ë²• íŒ¨í„´ {target_grammar} í•„ìˆ˜ í¬í•¨
3. ì œì‹œëœ ë‹¨ì–´ ë¬¸ì¥ í•˜ë‚˜ë‹¹ ìµœì†Œ 1ê°œì”© ê²¹ì¹˜ì§€ ì•Šê²Œ í•„ìˆ˜ í¬í•¨
4. ì•„ë˜ ì–´íœ˜Â·K-pop ê°•ì œ í• ë‹¹ì„ ë°˜ë“œì‹œ ì§€í‚¤ê¸°:
   ë¬¸ì¥1: '{w1}' í¬í•¨{kc1}
   ë¬¸ì¥2: '{w2}' í¬í•¨{kc2}
   ë¬¸ì¥3: '{w3}' í¬í•¨{kc3}

í˜•ì‹: ë²ˆí˜¸ ì—†ì´ ë¬¸ì¥ 3ê°œë§Œ
""",
            "intermediate": """
[ROLE]
ë„ˆëŠ” ì¤‘ê¸‰ í•œêµ­ì–´ í•™ìŠµìë¥¼ ìœ„í•œ ê²½í—˜ ë§ì€ í•œêµ­ì–´ êµì‚¬ì•¼.

[INSTRUCTIONS]
- í•™ìŠµ ìˆ˜ì¤€: {difficulty_level} (Grade {target_grade})
- í•µì‹¬ ì–´íœ˜: {words_formatted}
- ëª©í‘œ ë¬¸ë²•: {target_grammar}
- K-pop ì°¸ê³ : {kpop_context_text}

[REQUIREMENTS]
1. ì¤‘ê¸‰ ìˆ˜ì¤€ì˜ ë¬¸ì¥ ìƒì„±
2. ë¬¸ë²• {target_grammar} í•„ìˆ˜ í¬í•¨
3. ì œì‹œëœ ì–´íœ˜ ë¬¸ì¥ë‹¹ ìµœì†Œ 1ê°œì”© ê²¹ì¹˜ì§€ ì•Šê²Œ í•„ìˆ˜ í¬í•¨
4. ì•„ë˜ ì–´íœ˜Â·K-pop ê°•ì œ í• ë‹¹ì„ ë°˜ë“œì‹œ ì§€í‚¤ê¸°:
   ë¬¸ì¥1: '{w1}' í¬í•¨{kc1}
   ë¬¸ì¥2: '{w2}' í¬í•¨{kc2}
   ë¬¸ì¥3: '{w3}' í¬í•¨{kc3}

ì¶œë ¥: ì˜ˆë¬¸ 3ê°œë§Œ (ë²ˆí˜¸ ì—†ì´)
""",
            "advanced": """
[ROLE]
ë„ˆëŠ” ê³ ê¸‰ í•œêµ­ì–´ í•™ìŠµìë¥¼ ìœ„í•œ ì „ë¬¸ êµìˆ˜ë‹¤.

[INSTRUCTIONS]
- í•™ìŠµ ìˆ˜ì¤€: {difficulty_level} (Grade {target_grade})
- í•µì‹¬ ì–´íœ˜: {words_formatted}
- í•µì‹¬ ë¬¸ë²•: {target_grammar}
- K-pop ì°¸ê³ : {kpop_context_text}

[REQUIREMENTS]
1. ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°
2. ë¬¸ë²• {target_grammar} í•„ìˆ˜ í¬í•¨í•´ì„œ ì‹¬í™” í™œìš©
3. ì œì‹œëœ ì–´íœ˜ ì¤‘ ë¬¸ì¥ë‹¹ ìµœì†Œ 1ê°œ ê²¹ì¹˜ì§€ ì•Šê²Œ í•„ìˆ˜ í¬í•¨
4. ì•„ë˜ ì–´íœ˜Â·K-pop ê°•ì œ í• ë‹¹ì„ ë°˜ë“œì‹œ ì§€í‚¤ê¸°:
   ë¬¸ì¥1: '{w1}' í¬í•¨{kc1}
   ë¬¸ì¥2: '{w2}' í¬í•¨{kc2}
   ë¬¸ì¥3: '{w3}' í¬í•¨{kc3}

ì¶œë ¥: ì˜ˆë¬¸ 3ê°œë§Œ
"""
        }
        
        template = prompt_templates.get(difficulty, prompt_templates["intermediate"])
        # ê°•ì œ í• ë‹¹ ë‹¨ì–´/K-pop ì¤€ë¹„
        w1 = (selected_words[0] if selected_words and len(selected_words) > 0 else '')
        w2 = (selected_words[1] if selected_words and len(selected_words) > 1 else w1)
        w3 = (selected_words[2] if selected_words and len(selected_words) > 2 else w2)

        def make_kpop_clause(idx):
            if not assigned_kpop or len(assigned_kpop) <= idx:
                return ""
            g = assigned_kpop[idx].get('group') or ''
            s = assigned_kpop[idx].get('song') or ''
            ms = assigned_kpop[idx].get('members') or []
            cs = assigned_kpop[idx].get('concepts') or []
            parts = []
            if g:
                parts.append(f"ê·¸ë£¹ '{g}'")
            if s:
                parts.append(f"ê³¡ëª… '{s}'")
            if ms:
                parts.append("ë©¤ë²„ " + ", ".join([f"'{m}'" for m in ms]))
            if cs:
                parts.append("ì»¨ì…‰ " + ", ".join([f"'{c}'" for c in cs]))
            if not parts:
                return ""
            return ", K-pop ê´€ë ¨ ìš”ì†Œ (" + " ë˜ëŠ” ".join(parts) + ") ì¤‘ í•˜ë‚˜ í¬í•¨"

        kc1 = make_kpop_clause(0)
        kc2 = make_kpop_clause(1)
        kc3 = make_kpop_clause(2)

        return template.format(
            difficulty_level=difficulty_guide.get(difficulty, difficulty),
            target_grade=target_grade,
            words_formatted=', '.join(words_formatted),
            target_grammar=target_grammar,
            kpop_context_text=kpop_context_text if kpop_context_text else "ì—†ìŒ",
            w1=w1,
            w2=w2,
            w3=w3,
            kc1=kc1,
            kc2=kc2,
            kc3=kc3
        )
    
    def _evaluate_sentences(self, sentences, target_grammar, vocab_list):
        """ìƒì„±ëœ ë¬¸ì¥ í‰ê°€"""
        if self.evaluator and sentences:
            try:
                print("\n   ğŸ“Š ìƒì„±ëœ ë¬¸ì¥ í’ˆì§ˆ í‰ê°€ ì¤‘...")
                evaluation_results = self.evaluator.evaluate_batch(
                    sentences,
                    grammar=target_grammar,
                    vocab=vocab_list
                )
                
                critique_summary = []
                for sent, eval_res in zip(sentences, evaluation_results):
                    critique_summary.append({
                        "sentence": sent,
                        "grammar_ok": eval_res.get("grammar_ok", False),
                        "vocab_ok": eval_res.get("vocab_ok", False)
                    })
                
                return critique_summary
                
            except Exception as e:
                print(f"   âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return [{"sentence": s} for s in sentences]
    
    def format_output(self, state: GraphState) -> GraphState:
        """ìµœì¢… ì¶œë ¥ í¬ë§·íŒ… ë° JSON ì €ì¥"""
        output = f"=== í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± ê²°ê³¼ ===\n"
        output += f"ë‚œì´ë„: {state['difficulty_level']}\n"
        
        if 'target_grade' in state:
            output += f"ë¬¸ë²• Grade: {state['target_grade']}\n"
        
        output += "\nìƒì„±ëœ ì˜ˆë¬¸:\n"
        for i, sentence in enumerate(state['generated_sentences'], 1):
            output += f"{i}. {sentence}\n"
        
        if 'sentence_data' in state and state['sentence_data']:
            saved_file = self._save_to_json(state['sentence_data'])
            output += f"\nì˜ˆë¬¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_file}\n"
        
        return {"final_output": output}
    
    def _save_to_json(self, sentence_data: dict) -> str:
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        out_dir = Path(SENTENCE_SAVE_DIR)
        out_dir.mkdir(parents=True, exist_ok=True)

        level = sentence_data.get("level", "grade1")
        title = sentence_data.get("title", "untitled")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        base = f"sentences_{level}_{title}_{timestamp}"
        safe_base = sanitize_filename(base)
        filepath = out_dir / f"{safe_base}.json"

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(sentence_data, f, ensure_ascii=False, indent=2)

        return str(filepath)


# =====================================
# Agentic RAG êµ¬í˜„ (ê°œì„  ë²„ì „)
# =====================================
class AgenticKoreanLearningNodes(KoreanLearningNodes):
    """Agentic RAG ë…¸ë“œ - ì¬ìƒì„± ë¡œì§ ìµœì í™”"""
    
    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        super().__init__(vocabulary_retriever, grammar_retriever, kpop_retriever, llm)
        self.query_agent = QueryAnalysisAgent(llm)
        self.quality_agent = QualityCheckAgent(llm)
    
    def analyze_query_agent(self, state: GraphState) -> GraphState:
        """ì¿¼ë¦¬ ë¶„ì„ ì—ì´ì „íŠ¸ ë…¸ë“œ"""
        print("\nğŸ” [Agent] Query Analysis")
        analysis = self.query_agent.analyze(state['input_text'])
        
        print(f"   Difficulty: {analysis['difficulty']}")
        print(f"   Topic: {analysis['topic']}")
        print(f"   Needs K-pop: {analysis.get('needs_kpop', False)}")
        print(f"   K-pop Groups: {analysis.get('kpop_groups', [])}")
        
        return {
            "difficulty_level": analysis['difficulty'],
            "query_analysis": analysis
        }
    
    def retrieve_kpop_mixed(self, state: GraphState) -> GraphState:
        """K-pop ê²€ìƒ‰ ë…¸ë“œ"""
        print("\nğŸµ [Agent] K-pop Retrieval")
        
        level = state['difficulty_level']
        query = state['input_text']
        
        kpop_db_docs = self.kpop_retriever.invoke(query, level)
        kpop_db_docs = kpop_db_docs[:5]
        print(f"   DB ê²€ìƒ‰: {len(kpop_db_docs)}ê°œ")
        
        return {"kpop_docs": kpop_db_docs}
    
    def check_quality_agent(self, state: GraphState) -> GraphState:
        """í’ˆì§ˆ ê²€ì¦ ì—ì´ì „íŠ¸ ë…¸ë“œ"""
        print("\nâœ… [Agent] í’ˆì§ˆ ê²€ì¦")
        
        query_analysis = state.get('query_analysis', {})
        needs_kpop = query_analysis.get('needs_kpop', False)
        
        result = self.quality_agent.check(
            vocab_count=len(state.get('vocabulary_docs', [])),
            grammar_count=len(state.get('grammar_docs', [])),
            kpop_db_count=len(state.get('kpop_docs', [])),
            needs_kpop=needs_kpop
        )
        
        print(f"   ì–´íœ˜: {result['vocab_count']}ê°œ")
        print(f"   ë¬¸ë²•: {result['grammar_count']}ê°œ")
        print(f"   K-pop: {result['kpop_db_count']}ê°œ")
        print(f"   ìƒíƒœ: {result['message']}")
        
        return {"quality_check": result}
    
    def generate_sentences_with_kpop(self, state):
        """
        ê°œì„ ëœ ë¬¸ì¥ ìƒì„± - 3ê°œ ë³´ì¥ ë° ë¦¬ì†ŒìŠ¤ ë¶„ë°°
        """
        import random
        print("\nâœï¸ [Agent] í•œêµ­ì–´ í•™ìŠµ ë¬¸ì¥ ìƒì„± (3ê°œ ë³´ì¥)")
        
        from utils import extract_words_from_docs, extract_grammar_with_grade
        
        # ë°ì´í„° ì¶”ì¶œ (ì •í™•íˆ 3ê°œì”©)
        words_info = extract_words_from_docs(state['vocabulary_docs'])[:3]
        grammar_info = extract_grammar_with_grade(state['grammar_docs'])[:1]
        
        query_analysis = state.get('query_analysis', {})
        needs_kpop = query_analysis.get('needs_kpop', False)
        specified_groups = query_analysis.get('kpop_groups', [])
        
        # K-pop ì •ë³´ ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)
        kpop_metadata, kpop_contexts = self._process_kpop_docs_enhanced(
            state.get('kpop_docs', [])[:3],
            specified_groups
        )
        
        # ê¸°ë³¸ ì •ë³´ ì„¤ì •
        vocab_list = [word for word, _ in words_info]
        # ì–´íœ˜ ë¶€ì¡±ì‹œ ì±„ìš°ê¸°
        while len(vocab_list) < 3:
            vocab_list.append(f"í•™ìŠµë‹¨ì–´{len(vocab_list)+1}")
        vocab_list = vocab_list[:3]  # ì •í™•íˆ 3ê°œ
        
        target_grammar = grammar_info[0]['grammar'] if grammar_info else "ê¸°ë³¸ ë¬¸ë²•"
        target_grade = grammar_info[0]['grade'] if grammar_info else 1
        difficulty = state['difficulty_level']
        
        print(f"   íƒ€ê²Ÿ: ë¬¸ë²• '{target_grammar}' + ì–´íœ˜ {vocab_list}")
        if needs_kpop and kpop_contexts:
            print(f"   K-pop ì»¨í…ìŠ¤íŠ¸: {len(kpop_contexts)}ê°œ")
        
        # 3ê°œ ë¬¸ì¥ ê°œë³„ ìƒì„±
        generated_sentences = []
        
        for i in range(3):
            # ê° ë¬¸ì¥ë³„ ë¦¬ì†ŒìŠ¤ í• ë‹¹
            vocab = vocab_list[i] if i < len(vocab_list) else vocab_list[0]
            kpop_ctx = kpop_contexts[i] if i < len(kpop_contexts) else None
            
            # ê°œë³„ ë¬¸ì¥ í”„ë¡¬í”„íŠ¸
            prompt = f"""í•œêµ­ì–´ í•™ìŠµìš© ë¬¸ì¥ 1ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.

ã€í•„ìˆ˜ ì¡°ê±´ã€‘
- ìˆ˜ì¤€: {difficulty} (TOPIK {target_grade})
- ë¬¸ë²•: '{target_grammar}' ë°˜ë“œì‹œ í¬í•¨
- ì–´íœ˜: '{vocab}' ë°˜ë“œì‹œ í¬í•¨"""
            
            if kpop_ctx:
                prompt += f"\n- K-pop: {kpop_ctx['display']} ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨"
            
            prompt += """

ã€ìš”êµ¬ì‚¬í•­ã€‘
- 10-20ì ê¸¸ì´
- ìì—°ìŠ¤ëŸ½ê³  ì‹¤ìš©ì ì¸ ë¬¸ì¥
- ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì—†ì´ ë¬¸ì¥ë§Œ

ë¬¸ì¥:"""
            
            try:
                response = self.llm.predict(prompt)
                sentence = response.strip().lstrip('0123456789.-) ').strip()
                
                if sentence and len(sentence) > 5:
                    generated_sentences.append(sentence)
                    print(f"      ë¬¸ì¥{i+1}: {sentence}")
                else:
                    # ë°±ì—… ë¬¸ì¥
                    if kpop_ctx:
                        fallback = f"{kpop_ctx['group']}ì˜ {vocab}{target_grammar} ì¢‹ì•„í•´ìš”."
                    else:
                        fallback = f"{vocab}{target_grammar} ì—°ìŠµí•´ìš”."
                    generated_sentences.append(fallback)
                    print(f"      ë¬¸ì¥{i+1} (ëŒ€ì²´): {fallback}")
            except Exception as e:
                print(f"      ë¬¸ì¥{i+1} ìƒì„± ì˜¤ë¥˜: {e}")
                fallback = f"{vocab}{target_grammar} ê³µë¶€í•©ë‹ˆë‹¤."
                generated_sentences.append(fallback)
        
        # ì •í™•íˆ 3ê°œ ë³´ì¥
        while len(generated_sentences) < 3:
            fallback = f"{target_grammar} íŒ¨í„´ ì˜ˆë¬¸ì…ë‹ˆë‹¤."
            generated_sentences.append(fallback)
        generated_sentences = generated_sentences[:3]
        
        print(f"   âœ… ìµœì¢… ìƒì„±: {len(generated_sentences)}ê°œ ë¬¸ì¥")
        
        # ë°ì´í„° ì €ì¥
        sentence_data = {
            "level": f"grade{target_grade}",
            "title": sanitize_filename(state['input_text'][:50]),
            "target_grammar": target_grammar,
            "vocabulary": vocab_list,
            "critique_summary": [
                {
                    "sentence": sent,
                    "vocab_used": vocab_list[i] if i < len(vocab_list) else "",
                    "kpop_context": kpop_contexts[i]['display'] if i < len(kpop_contexts) else ""
                }
                for i, sent in enumerate(generated_sentences)
            ]
        }
        
        if kpop_metadata:
            sentence_data["kpop_references"] = kpop_metadata
        
        return {
            "generated_sentences": generated_sentences,
            "sentence_data": sentence_data,
            "target_grade": target_grade
        }

    def _process_kpop_docs_enhanced(self, kpop_docs, specified_groups):
        """K-pop ë¬¸ì„œ ì²˜ë¦¬ - ë‹¤ì–‘í•œ í•„ë“œ í™œìš© ë²„ì „"""
        import random
        
        kpop_metadata = []
        kpop_contexts = []  # ê° ë¬¸ì¥ë³„ K-pop ì»¨í…ìŠ¤íŠ¸
        
        if not kpop_docs:
            return kpop_metadata, kpop_contexts
        
        # í•„í„°ë§ (specified_groupsê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê·¸ë£¹ë§Œ)
        filtered_docs = kpop_docs[:3]
        if specified_groups:
            filtered = []
            for doc in kpop_docs:
                group = doc.metadata.get('group', '')
                if any(g.upper() == group.upper() for g in specified_groups):
                    filtered.append(doc)
            if filtered:
                filtered_docs = filtered[:3]
        
        # ê° ë¬¸ì„œë³„ë¡œ ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        for doc in filtered_docs:
            meta = doc.metadata
            group = meta.get('group', '')
            
            if not group:
                continue
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            full_meta = {
                "group": group,
                "agency": meta.get('agency', ''),
                "fandom": meta.get('fandom', ''),
                "concepts": meta.get('concepts', []),
                "members": [m.get("name", "") for m in meta.get('members', [])[:3]]
            }
            kpop_metadata.append(full_meta)
            
            # ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ ì˜µì…˜ ìƒì„±
            context_options = []
            
            # 1. ê·¸ë£¹ëª… ì»¨í…ìŠ¤íŠ¸
            context_options.append({
                'type': 'group',
                'display': f"{group}",
                'group': group
            })
            
            # 2. ë©¤ë²„ ì»¨í…ìŠ¤íŠ¸
            members = meta.get('members', [])
            if members:
                member = random.choice(members[:5])
                member_name = member.get('name', '')
                if member_name:
                    context_options.append({
                        'type': 'member',
                        'display': f"{group}ì˜ {member_name}",
                        'group': group
                    })
            
            # 3. íŒ¬ë¤ ì»¨í…ìŠ¤íŠ¸
            fandom = meta.get('fandom', '')
            if fandom:
                context_options.append({
                    'type': 'fandom',
                    'display': f"{group} íŒ¬ë¤ {fandom}",
                    'group': group
                })
            
            # 4. ì†Œì†ì‚¬ ì»¨í…ìŠ¤íŠ¸
            agency = meta.get('agency', '')
            if agency:
                context_options.append({
                    'type': 'agency',
                    'display': f"{agency} ì†Œì† {group}",
                    'group': group
                })
            
            # 5. ì»¨ì…‰ ì»¨í…ìŠ¤íŠ¸
            concepts = meta.get('concepts', [])
            if concepts:
                concept = random.choice(concepts)
                context_options.append({
                    'type': 'concept',
                    'display': f"{concept} ì»¨ì…‰ì˜ {group}",
                    'group': group
                })
            
            # ëœë¤í•˜ê²Œ í•˜ë‚˜ ì„ íƒ
            if context_options:
                selected = random.choice(context_options)
                kpop_contexts.append(selected)
        
        # 3ê°œ ë§ì¶”ê¸° (ë¶€ì¡±í•˜ë©´ ë°˜ë³µ)
        while len(kpop_contexts) < 3 and kpop_contexts:
            kpop_contexts.append(random.choice(kpop_contexts))
        
        return kpop_metadata, kpop_contexts


    def _calculate_score(self, critique, kpop_ok):
        # ìš°ì„  ì¿¼ë¦¬ì—ì„œ ì‹ë³„ëœ ê·¸ë£¹ìœ¼ë¡œ í•„í„°ë§, ì—†ìœ¼ë©´ ìƒìœ„ ê²°ê³¼ ì‚¬ìš©
        if kpop_groups:
            kpool = [d for d in kdocs_all if (d.metadata.get('group', '') or '').upper() in {g.upper() for g in kpop_groups}][:5]
        else:
            kpool = kdocs_all[:5]
        seen_keys = set()
        for d in kpool:
            group = (d.metadata.get('group', '') or '').strip()
            song = (d.metadata.get('song', '') or '').strip()
            members = [m.get('name', '').strip() for m in (d.metadata.get('members', []) or []) if m.get('name')]
            concepts = [c.strip() for c in (d.metadata.get('concepts', []) or []) if isinstance(c, str) and c.strip()]
            key = group.lower() if group else (song.lower() if song else None)
            if not key or key in seen_keys:
                continue
            seen_keys.add(key)
            assigned_kpop.append({
                'group': group,
                'song': song,
                'members': members[:3],
                'concepts': concepts[:3]
            })
            if len(assigned_kpop) >= 3:
                break
        
        # ===================================
        # 3íšŒ ì‹œë„, ê°€ì¥ ì¢‹ì€ ê²°ê³¼ ì„ íƒ
        # ===================================
        max_attempts = 3
        all_attempts = []
        
        for attempt in range(max_attempts):
            print(f"\n   ğŸ“ ì‹œë„ {attempt + 1}/{max_attempts}")
            
            # ì ì§„ì ìœ¼ë¡œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_progressive_prompt(
                attempt,
                difficulty,
                target_grade,
                target_grammar,
                vocab_list,
                kpop_groups,
                kpop_context_text,
                needs_kpop,
                assigned_kpop,
                all_attempts  # ì´ì „ ì‹¤íŒ¨ ì •ë³´
            )
            
            # ë¬¸ì¥ ìƒì„±
            response = self.llm.predict(prompt)
            sentences = [s.strip() for s in response.strip().split('\n') if s.strip()][:3]
            
            # í‰ê°€ ìˆ˜í–‰
            critique = self._evaluate_sentences(sentences, target_grammar, vocab_list)
            
            # K-pop í¬í•¨ ì²´í¬ (ë¬¸ì¥ë³„ í• ë‹¹ ê¸°ì¤€)
            if needs_kpop and assigned_kpop:
                kpop_ok = self._check_kpop_assigned(sentences, assigned_kpop)
            elif needs_kpop:
                kpop_ok = self._check_kpop_inclusion(sentences, kpop_groups)
            else:
                kpop_ok = True
            
            # ì ìˆ˜ ê³„ì‚°
            score = self._calculate_score(critique, kpop_ok)
            
            all_attempts.append({
                'sentences': sentences,
                'critique': critique,
                'score': score,
                'kpop_ok': kpop_ok
            })
            
            print(f"      ì ìˆ˜: {score}/3 (ë¬¸ë²•+ì–´íœ˜+K-pop)")
            
            # ì™„ë²½í•œ ê²°ê³¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
            if score == 3:
                print(f"   âœ… ì™„ë²½í•œ ë¬¸ì¥ ìƒì„±!")
                break
        
        # ê°€ì¥ ì¢‹ì€ ê²°ê³¼ ì„ íƒ
        best_attempt = max(all_attempts, key=lambda x: x['score'])
        final_sentences = best_attempt['sentences']
        critique_summary = best_attempt['critique']
        
        print(f"\n   ğŸ† ìµœì¢… ì„ íƒ: ì ìˆ˜ {best_attempt['score']}/3")
        
        # JSON ì €ì¥ ë°ì´í„°
        save_data = {
            "level": target_grade,
            "target_grammar": target_grammar,
            "kpop_references": kpop_metadata,
            "specified_groups": specified_groups,
            "critique_summary": critique_summary
        }
        
        messages = [
            ("user", state['input_text']),
            ("assistant", "\n".join(final_sentences))
        ]
        
        return {
            "generated_sentences": final_sentences,
            "messages": messages,
            "sentence_data": save_data,
            "target_grade": target_grade
        }
    
    def _calculate_score(self, critique, kpop_ok):
        """
        ë¬¸ì¥ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        - ë¬¸ë²• ì¶©ì¡±: +1ì 
        - ì–´íœ˜ ì¶©ì¡±: +1ì 
        - K-pop í¬í•¨ (í•„ìš”ì‹œ): +1ì 
        """
        grammar_pass = sum(1 for c in critique if c.get('grammar_ok', False))
        vocab_pass = sum(1 for c in critique if c.get('vocab_ok', False))
        
        score = 0
        if grammar_pass == 3:  # 3ê°œ ë¬¸ì¥ ëª¨ë‘ ë¬¸ë²• ì¶©ì¡±
            score += 1
        if vocab_pass == 3:    # 3ê°œ ë¬¸ì¥ ëª¨ë‘ ì–´íœ˜ ì¶©ì¡±
            score += 1
        if kpop_ok:             # K-pop ì¡°ê±´ ì¶©ì¡±
            score += 1
        
        return score
    
    def _build_progressive_prompt(self, *args, **kwargs):
        """ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - generate_sentences_with_kpopì—ì„œ ì§ì ‘ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return ""
    
    def _process_kpop_docs(self, kpop_docs, specified_groups):
        """K-pop ë¬¸ì„œ ì²˜ë¦¬ ë° í•„í„°ë§"""
        kpop_metadata = []
        kpop_context_text = ""
        kpop_groups = []
        
        if not kpop_docs:
            return kpop_metadata, kpop_context_text, kpop_groups
        
        # í•„í„°ë§
        filtered_docs = kpop_docs[:3]
        if specified_groups:
            filtered = []
            for doc in kpop_docs:
                group = doc.metadata.get('group', '')
                if any(g.upper() == group.upper() for g in specified_groups):
                    filtered.append(doc)
            
            if filtered:
                filtered_docs = filtered[:3]
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        for doc in filtered_docs:
            group = doc.metadata.get('group', '')
            if group:
                kpop_groups.append(group)
                
                meta = {
                    "group": group,
                    "agency": doc.metadata.get('agency', ''),
                    "fandom": doc.metadata.get('fandom', ''),
                    "concepts": doc.metadata.get('concepts', []),
                    "members": [m.get("name", "") for m in doc.metadata.get('members', [])[:4]]
                }
                kpop_metadata.append(meta)
                
                # ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
                kpop_context_text += f"ã€{group}ã€‘\n"
                if meta['agency']:
                    kpop_context_text += f"  ì†Œì†ì‚¬: {meta['agency']}\n"
                if meta['fandom']:
                    kpop_context_text += f"  íŒ¬ë¤: {meta['fandom']}\n"
                if meta['concepts']:
                    kpop_context_text += f"  ì»¨ì…‰: {', '.join(meta['concepts'])}\n"
                if meta['members']:
                    kpop_context_text += f"  ë©¤ë²„: {', '.join(meta['members'])}\n"
                kpop_context_text += "\n"
        
        return kpop_metadata, kpop_context_text, kpop_groups
    
    def _check_kpop_inclusion(self, sentences, kpop_groups):
        """K-pop ê·¸ë£¹ëª… í¬í•¨ ì—¬ë¶€ ì²´í¬"""
        if not kpop_groups:
            return True
        
        # ì˜ì–´ ê·¸ë£¹ëª…ì˜ í•œê¸€ ë³€í™˜ ë§¤í•‘
        korean_names = {
            "BLACKPINK": "ë¸”ë™í•‘í¬",
            "BTS": "ë°©íƒ„ì†Œë…„ë‹¨",
            "TWICE": "íŠ¸ì™€ì´ìŠ¤",
            "NewJeans": "ë‰´ì§„ìŠ¤",
            "EXO": "ì—‘ì†Œ",
            "Stray Kids": "ìŠ¤íŠ¸ë ˆì´í‚¤ì¦ˆ",
            "aespa": "ì—ìŠ¤íŒŒ",
            "SEVENTEEN": "ì„¸ë¸í‹´"
        }
        
        # ëª¨ë“  ë¬¸ì¥ì—ì„œ K-pop ì •ë³´ í¬í•¨ í™•ì¸
        for sentence in sentences:
            has_kpop = False
            for group in kpop_groups:
                # ì˜ì–´ëª… ë˜ëŠ” í•œê¸€ëª… ì²´í¬
                if (group.lower() in sentence.lower() or 
                    korean_names.get(group, "").lower() in sentence.lower()):
                    has_kpop = True
                    break
            
            if not has_kpop:
                return False
        
        return True

    def _check_kpop_assigned(self, sentences, assigned_kpop):
        """ë¬¸ì¥ë³„ë¡œ í• ë‹¹ëœ K-pop ìš”ì†Œ(ê·¸ë£¹/ê³¡ëª…/ë©¤ë²„/ì»¨ì…‰) í¬í•¨ ì—¬ë¶€ ì²´í¬"""
        if not sentences or not assigned_kpop:
            return True
        for idx, sentence in enumerate(sentences[:3]):
            if idx >= len(assigned_kpop):
                continue
            ctx = assigned_kpop[idx]
            sent_lower = sentence.lower()
            group = (ctx.get('group') or '').lower()
            song = (ctx.get('song') or '').lower()
            members = [(m or '').lower() for m in (ctx.get('members') or [])]
            concepts = [(c or '').lower() for c in (ctx.get('concepts') or [])]

            included = False
            if group and group in sent_lower:
                included = True
            if not included and song and song in sent_lower:
                included = True
            if not included and any(m and m in sent_lower for m in members):
                included = True
            if not included and any(c and c in sent_lower for c in concepts):
                included = True
            if not included:
                return False
        return True

    def format_output_agentic(self, state: GraphState) -> GraphState:
        """Agentic RAG ì¶œë ¥ í¬ë§·íŒ…"""
        print("\nğŸ“„ [Agent] ìµœì¢… ì¶œë ¥")
        
        output = "=" * 80 + "\n"
        output += "ğŸ“ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± (Agentic RAG)\n"
        output += "=" * 80 + "\n\n"
        
        # ìƒì„±ëœ ë¬¸ì¥
        sentences = state.get('generated_sentences', [])
        if sentences:
            output += "ã€ìƒì„±ëœ í•™ìŠµ ì˜ˆë¬¸ã€‘\n"
            for i, sentence in enumerate(sentences, 1):
                output += f"   {i}. {sentence}\n"
        
        # íŒŒì¼ ì €ì¥
        if 'sentence_data' in state and state['sentence_data']:
            saved_file = self._save_to_json(state['sentence_data'])
            output += f"\nğŸ’¾ ì €ì¥: {saved_file}\n"
        
        output += "\n" + "=" * 80 + "\n"
        
        return {"final_output": output}