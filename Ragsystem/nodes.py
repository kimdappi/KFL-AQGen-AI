# =====================================
# nodes.py (Updated) - gradeë¥¼ levelë¡œ ì‚¬ìš©
# ìˆ˜ì • ì™„ë£Œ
# =====================================
"""
LangGraph ë…¸ë“œ ì •ì˜ (ë¬¸ì¥ ì €ì¥ ê¸°ëŠ¥ ë° grade ì‚¬ìš©)
"""
import json
import os
import re
import random
from typing import List, Dict, Any
from pathlib import Path
from datetime import datetime
from typing import Any
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from Ragsystem.schema import GraphState #ë””ë ‰í† ë¦¬ êµ¬ì¡° ì •ë¦¬
from utils import (#ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë§Œ ì„ ì–¸í•´ë„ ë¨
    detect_difficulty_from_text,
    extract_words_from_docs,
    extract_grammar_with_grade  
    #extract_grammars_from_docs, format_docs # í˜„ì¬ ì•ˆì“°ëŠ” í•¨ìˆ˜
)
from config import LLM_CONFIG,SENTENCE_SAVE_DIR #ë¬¸ì¥ ì €ì¥ê²½ë¡œ ë³€ê²½
from agents import QueryAnalysisAgent, QualityCheckAgent

INVALID_CHARS = r'[<>:"/\\|?*\x00-\x1F]'

def sanitize_filename(name: str, replacement: str = "_") -> str:
# ê¸ˆì§€ë¬¸ì -> _
    safe = re.sub(INVALID_CHARS, replacement, name)
    # ë§ˆì§€ë§‰ì˜ ì /ê³µë°± ì œê±°
    safe = safe.strip().strip(".")
    # Windows ì˜ˆì•½ì–´ íšŒí”¼
    RESERVED = {"CON","PRN","AUX","NUL",*(f"COM{i}" for i in range(1,10)),*(f"LPT{i}" for i in range(1,10))}
    if safe.upper() in RESERVED:
        safe = f"_{safe}"
        # ë„ˆë¬´ ê¸´ íŒŒì¼ëª… ë°©ì§€ (ê²½ë¡œ ì „ì²´ ê¸¸ì´ ì—¬ìœ  ì£¼ê¸°)
    return safe[:120] if len(safe) > 120 else safe

class KoreanLearningNodes:
    """í•œêµ­ì–´ í•™ìŠµ ë…¸ë“œ í´ë˜ìŠ¤"""
    
    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        self.vocabulary_retriever = vocabulary_retriever
        self.grammar_retriever = grammar_retriever
        self.kpop_retriever = kpop_retriever  # âœ… ì¶”ê°€
        self.llm = llm or ChatOpenAI(
            model="gpt-4o-mini", #ë²”ì¤€ì´ api ëŒ€ì‹  ì„ì‹œ
            temperature=LLM_CONFIG.get('temperature', 0.7),
            max_tokens=LLM_CONFIG.get('max_tokens', 1000)
        )
        
        # sentence í´ë” ìƒì„±
        self.output_dir = "sentence"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def detect_difficulty(self, state: GraphState) -> GraphState:
        """ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ë‚œì´ë„ ê°ì§€"""
        difficulty = detect_difficulty_from_text(state['input_text'])
        return {"difficulty_level": difficulty}
    
    def retrieve_vocabulary(self, state: GraphState) -> GraphState:
        """ë‹¨ì–´ ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']
        
        vocab_docs = self.vocabulary_retriever.invoke(query, level)
        return {"vocabulary_docs": vocab_docs}

    def retrieve_kpop(self, state: GraphState) -> GraphState:
        """K-pop ë¬¸ì¥ ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']

        kpop_docs = self.kpop_retriever.invoke(query, level)
        return {"kpop_docs": kpop_docs}
    
    
    def retrieve_grammar(self, state: GraphState) -> GraphState:
        """ë¬¸ë²• ê²€ìƒ‰ ë…¸ë“œ"""
        level = state['difficulty_level']
        query = state['input_text']
        
        grammar_docs = self.grammar_retriever.invoke(query, level)
        return {"grammar_docs": grammar_docs}

    def generate_sentences(self, state: GraphState) -> GraphState:
        """ê²€ìƒ‰ëœ ë‹¨ì–´ì™€ ë¬¸ë²•ì„ í™œìš©í•œ ë¬¸ì¥ ìƒì„± (K-pop ì •ë³´ í¬í•¨)"""
        words_info = extract_words_from_docs(state['vocabulary_docs'])

        # âœ… K-pop ì •ë³´ ì¶”ì¶œ ë° í¬ë§·íŒ…
        kpop_references = []
        kpop_context_text = ""
        
        if 'kpop_docs' in state and state['kpop_docs']:
            print(f"[ì°¸ì¡°] K-pop ë¬¸ì„œ ê°œìˆ˜: {len(state['kpop_docs'])}")
            
            for doc in state['kpop_docs'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                sentence = doc.metadata.get('sentence', '')
                song = doc.metadata.get('song', '')
                group = doc.metadata.get('group', '')
                
                if sentence:
                    kpop_references.append({
                        "sentence": sentence,
                        "song": song,
                        "group": group,
                    })

                    kpop_context_text += f'- "{sentence}" ({song} - {group})\n'
        
        print(f"[ì°¸ì¡°] K-pop ì°¸ì¡° ê°œìˆ˜: {len(kpop_references)}")
        
        # ë¬¸ë²•ê³¼ grade ì •ë³´ í•¨ê»˜ ì¶”ì¶œ
        grammar_info = extract_grammar_with_grade(state['grammar_docs'])
        
        # ë‹¨ì–´ì™€ í’ˆì‚¬ ì •ë³´ í¬ë§·íŒ…
        words_formatted = []
        for word, wordclass in words_info[:5]:
            words_formatted.append(f"{word}({wordclass})")
        
        if grammar_info:
            # ê²€ìƒ‰ëœ ë¬¸ë²• ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¬´ì‘ìœ„ë¡œ í•˜ë‚˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
            random_grammar_item = random.choice(grammar_info)
            target_grammar = random_grammar_item['grammar']
            target_grade = random_grammar_item['grade']
            print("grammer : ", target_grammar)
            print("grade : ", target_grade)
        else:
            target_grammar = "ê¸°ë³¸ ë¬¸ë²•"
            target_grade = 1
        
        
        prompt = f"""
                ë‹¤ìŒ ë‹¨ì–´ì™€ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í•™ìŠµìš© ì˜ˆë¬¸ì„ 3ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.
                
                ë‚œì´ë„: {state['difficulty_level']} (Grade {target_grade})
                ë‹¨ì–´ (í’ˆì‚¬): {', '.join(words_formatted)}
                í•™ìŠµ ëª©í‘œ ë¬¸ë²•: {target_grammar} (Grade {target_grade})
                
                
                ê° ë¬¸ì¥ì€:
                1. ì œì‹œëœ ë‹¨ì–´ë¥¼ ìµœì†Œ 5ê°œ ì´ìƒ í¬í•¨
                2. ì£¼ìš” ë¬¸ë²• íŒ¨í„´ì„ ë°˜ë“œì‹œ í¬í•¨
                3. Grade {target_grade} ìˆ˜ì¤€ì— ì í•©í•œ ë³µì¡ë„
                4. ì™¸êµ­ì¸ì´ í•œêµ­ì–´ë¥¼ ë°°ìš¸ ë•Œ ìœ ìš©í•œ ë¬¸ì¥
                5. ì‚¬ìš©ì ì§€ì • ê´€ì‹¬ì‚¬ì¸ {kpop_context_text} ë°˜ì˜í•´ì„œ ë¬¸ì¥ ìƒì„±
                
                ì˜ˆë¬¸ (ë²ˆí˜¸ ì—†ì´ ë¬¸ì¥ë§Œ):
                """
                
                # --- START: ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° ë¡œì§ ---
        difficulty = state['difficulty_level']

                # ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        prompt_templates = {
                    "basic": """
        [ROLE]
        ë„ˆëŠ” ì´ì œ ë§‰ í•œêµ­ì–´ë¥¼ ë°°ìš°ê¸° ì‹œì‘í•œ 7ì‚´ ì™¸êµ­ì¸ ì•„ì´ë“¤ì„ ê°€ë¥´ì¹˜ëŠ” **ì•„ì£¼ ì¹œì ˆí•˜ê³  ìƒëƒ¥í•œ ìœ ì¹˜ì› ì„ ìƒë‹˜**ì´ì•¼. ì•„ì´ë“¤ì˜ ëˆˆë†’ì´ì— ë§ì¶°, ì„¸ìƒì—ì„œ ê°€ì¥ ì‰½ê³  ì¬ë¯¸ìˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜ì•¼ í•´.

        [INSTRUCTIONS]
        - **ë¯¸ì…˜**: ì•„ë˜ì˜ ë‹¨ì–´ì™€ ë¬¸ë²•ìœ¼ë¡œ, ì•„ì´ë“¤ì´ "í•œêµ­ì–´ ì •ë§ ì¬ë¯¸ìˆë‹¤!"ë¼ê³  ëŠë‚„ ë§Œí•œ ì˜ˆë¬¸ 3ê°œë¥¼ ë§Œë“¤ì–´ì¤˜.
        - **í•™ìŠµ ìˆ˜ì¤€**: {difficulty_level} (TOPIK 1~2ê¸‰, Grade {target_grade})
        - **ì˜¤ëŠ˜ì˜ ë‹¨ì–´**: {words_formatted}
        - **ì˜¤ëŠ˜ì˜ ë¬¸ë²•**: `{target_grammar}`
        - **ì•„ì´ë“¤ì˜ ê´€ì‹¬ì‚¬ (K-pop)**: {kpop_context_text}

        [SENTENCE RULES]
        1.  **ì‰¬ìš´ ë‹¨ì–´ë§Œ!**: 'ì˜¤ëŠ˜ì˜ ë‹¨ì–´' ì™¸ì—ëŠ” ì•„ì´ë“¤ë„ ì•„ëŠ” ì•„ì£¼ ê¸°ë³¸ì ì¸ ë‹¨ì–´ë§Œ ì‚¬ìš©í•´. (ì˜ˆ: ì‚¬ê³¼, ê°€ë‹¤, ë¨¹ë‹¤, í¬ë‹¤)
        2.  **ì§§ì€ ë¬¸ì¥!**: ë¬¸ì¥ì€ ë¬´ì¡°ê±´ ì§§ê³  ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì¤˜. (ì˜ˆ: ì£¼ì–´ + ëª©ì ì–´ + ë™ì‚¬)
        3.  **ì¬ë¯¸ìˆê²Œ!**: ì•„ì´ë“¤ì˜ ê´€ì‹¬ì‚¬ì¸ K-pop ê°€ìˆ˜ ì´ë¦„ì´ë‚˜ ë…¸ë˜ ì œëª©ì„ ë„£ì–´ì„œ ì¬ë¯¸ìˆê²Œ ë§Œë“¤ì–´ì¤˜.
        4.  **ì •í™•í•œ ë¬¸ë²•!**: 'ì˜¤ëŠ˜ì˜ ë¬¸ë²•'ì¸ `{target_grammar}`ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•´ì•¼ í•´. ë§Œì•½ ë¬¸ë²•ì´ ë™ì‚¬ë¥¼ í•„ìš”ë¡œ í•˜ë©´, ì£¼ì–´ì§„ ë‹¨ì–´ì™€ ì–´ìš¸ë¦¬ëŠ” ë™ì‚¬(ì˜ˆ: ê³µë¶€í•˜ë‹¤, ìˆ™ì œí•˜ë‹¤)ë¥¼ ì°¾ì•„ì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜.
        5.  **ìì—°ìŠ¤ëŸ½ê²Œ!**: ë‹¨ì–´ë“¤ì„ ì–µì§€ë¡œ ì¡°í•©í•˜ì§€ ë§ê³ , ì‹¤ì œ í•œêµ­ì¸ë“¤ì´ ì‚¬ìš©í•  ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜.

        [OUTPUT FORMAT]
        - ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ê³ , ì˜ˆë¬¸ 3ê°œë§Œ í•œ ì¤„ì”© ë°”ë¡œ ì¶œë ¥í•´ì¤˜.

        [ì˜ˆë¬¸ ì‹œì‘]
        """,
            "intermediate": """
        [ROLE]
        ë„ˆëŠ” í•œêµ­ì–´í•™ë‹¹ì—ì„œ ì¤‘ê¸‰ íšŒí™” ìˆ˜ì—…ì„ ë‹´ë‹¹í•˜ëŠ” **ì‹¤ë ¥ ìˆê³  ê²½í—˜ ë§ì€ í•œêµ­ì–´ êµì‚¬**ì•¼. í•™ìƒë“¤ì´ ìˆ˜ì—…ì´ ëë‚˜ê³  ë°”ë¡œ ì‹¤ìƒí™œì—ì„œ ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” ìœ ìš©í•œ ë¬¸ì¥ì„ ë§Œë“œëŠ” ê²ƒì´ ë„ˆì˜ ì—­í• ì´ì•¼.

        [INSTRUCTIONS]
        - **ëª©í‘œ**: ì•„ë˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬, ì¤‘ê¸‰ í•™ìŠµì(TOPIK 3~4ê¸‰)ê°€ ì¹œêµ¬ì™€ ëŒ€í™”í•˜ê±°ë‚˜ ì¼ìƒìƒí™œì—ì„œ ê²ªëŠ” ìƒí™©ì— ë§ëŠ” ì‹¤ìš©ì ì¸ ì˜ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì¤˜.
        - **í•™ìŠµ ìˆ˜ì¤€**: {difficulty_level} (TOPIK 3~4ê¸‰, Grade {target_grade})
        - **í•µì‹¬ ì–´íœ˜**: {words_formatted}
        - **ëª©í‘œ ë¬¸ë²•**: `{target_grammar}`
        - **í•™ìƒ ê´€ì‹¬ì‚¬ (K-pop)**: {kpop_context_text}

        [SENTENCE REQUIREMENTS]
        0.  **ë¬¸ë²• ì¤€ìˆ˜**: ìƒì„±í•˜ëŠ” ëª¨ë“  ë¬¸ì¥ì—ëŠ” ëª©í‘œ ë¬¸ë²•ì¸ `{target_grammar}`ê°€ **ë°˜ë“œì‹œ** í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.
        1.  **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´**: ì‹¤ì œ í•œêµ­ì¸ë“¤ì´ ì¹œêµ¬ì™€ ëŒ€í™”í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ì™€ ì–µì–‘ì„ ì‚´ë ¤ì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜.
        2.  **ë¬¸ë²• í™œìš©**: `{target_grammar}` ë¬¸ë²•ì˜ ì˜ë¯¸ì™€ ì“°ì„ì´ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚˜ëŠ” ë¬¸ë§¥ì„ ì œì‹œí•´ì¤˜.
        3.  **ë¬¸ë§¥ì˜ êµ¬ì²´ì„±**: K-pop ë…¸ë˜ë¥¼ ë“£ê³  ê°ìƒì„ ë§í•˜ê±°ë‚˜, ì½˜ì„œíŠ¸ì— ê°€ëŠ” ê³„íšì„ ì„¸ìš°ëŠ” ë“± êµ¬ì²´ì ì¸ ìƒí™©ì„ ì„¤ì •í•´ì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜.
        4.  **ì ì ˆí•œ ë³µì¡ë„**: ë‘ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ëŠ” ë“± Grade {target_grade} ìˆ˜ì¤€ì— ë§ëŠ” ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ì¤˜.

        [OUTPUT FORMAT]
        - ë²ˆí˜¸ë‚˜ ë¶€ê°€ ì„¤ëª… ì—†ì´, ìƒì„±ëœ ì˜ˆë¬¸ 3ê°œë§Œ í•œ ì¤„ì”© ì¶œë ¥í•´ì¤˜.

        [ì˜ˆë¬¸ ì‹œì‘]
        """,
            "advanced": """
        [ROLE]
        ë„ˆëŠ” í•œêµ­í•™ì„ ì „ê³µí•˜ëŠ” ì™¸êµ­ì¸ ì„ë°•ì‚¬ ê³¼ì • í•™ìƒë“¤ì˜ ë…¼ë¬¸ ì§€ë„ë¥¼ ë‹´ë‹¹í•˜ëŠ” **ë§¤ìš° ì „ë¬¸ì ì´ê³  ë…¼ë¦¬ì ì¸ êµ­ì–´êµ­ë¬¸í•™ê³¼ êµìˆ˜**ë‹¤. ë„ˆì˜ ëª©í‘œëŠ” í•™ìƒë“¤ì´ ë³µì¡í•œ ìƒê°ê³¼ ì£¼ì¥ì„ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê¹Šì´ ìˆê²Œ í‘œí˜„í•˜ë„ë¡ ë•ëŠ” ê²ƒì´ë‹¤.

        [INSTRUCTIONS]
        - **ê³¼ì œ**: ì•„ë˜ì˜ í•µì‹¬ ì–´íœ˜ì™€ ë¬¸ë²•ì„ ë°”íƒ•ìœ¼ë¡œ, ê³ ê¸‰ í•™ìŠµì(TOPIK 5~6ê¸‰)ê°€ í•™ìˆ ì ì¸ í† ë¡ ì´ë‚˜ ê²©ì‹ ìˆëŠ” ê¸€ì“°ê¸°ì—ì„œ ì‚¬ìš©í•  ë§Œí•œ ìˆ˜ì¤€ ë†’ì€ ì˜ˆë¬¸ 3ê°œë¥¼ ì‘ì„±í•˜ë¼.
        - **í•™ìŠµ ìˆ˜ì¤€**: {difficulty_level} (TOPIK 5~6ê¸‰, Grade {target_grade})
        - **í•µì‹¬ ì–´íœ˜**: {words_formatted}
        - **í•µì‹¬ ë¬¸ë²•**: `{target_grammar}`
        - **ì°¸ê³  ìë£Œ (K-pop)**: {kpop_context_text}

        [SENTENCE REQUIREMENTS]
        0.  **ë¬¸ë²• ì¤€ìˆ˜**: ìƒì„±í•˜ëŠ” ëª¨ë“  ë¬¸ì¥ì—ëŠ” ëª©í‘œ ë¬¸ë²•ì¸ `{target_grammar}`ê°€ **ë°˜ë“œì‹œ** í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.
        1.  **ê²©ì‹ê³¼ ë…¼ë¦¬**: ë¬¸ì–´ì²´ í˜¹ì€ ê²©ì‹ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¦¬ì ì´ê³  ê°ê´€ì ì¸ ì‚¬ì‹¤ì´ë‚˜ ì£¼ì¥ì„ ì„œìˆ í•˜ëŠ” ë¬¸ì¥ì„ êµ¬ì„±í•˜ë¼.
        2.  **ì–´íœ˜ ìˆ˜ì¤€**: ì œì‹œëœ ì–´íœ˜ ì™¸ì—ë„ í•´ë‹¹ ì£¼ì œë¥¼ ë…¼ì˜í•˜ëŠ” ë° í•„ìš”í•œ ê³ ê¸‰ ì–´íœ˜ë‚˜ ì ì ˆí•œ í•œìì–´ë¥¼ ì‚¬ìš©í•˜ë¼.
        3.  **ë¬¸ë²•ì˜ ê¹Šì´**: `{target_grammar}` ë¬¸ë²•ì´ ê°€ì§„ ë¯¸ë¬˜í•œ ë‰˜ì•™ìŠ¤ë‚˜ ì‹¬í™”ëœ ì“°ì„ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” ë³µí•©ì ì¸ ë¬¸ì¥ì„ ë§Œë“¤ì–´ë¼.
        4.  **ì£¼ì œì˜ ì‹¬ì¸µ ë¶„ì„**: ì°¸ê³  ìë£Œì¸ K-popì„ ë‹¨ìˆœí•œ í¥ë°‹ê±°ë¦¬ê°€ ì•„ë‹Œ, í•˜ë‚˜ì˜ ì‚¬íšŒÂ·ë¬¸í™”ì  í˜„ìƒìœ¼ë¡œ ë¶„ì„í•˜ê±°ë‚˜ ë¹„í‰í•˜ëŠ” ê´€ì ì˜ ë¬¸ì¥ì„ ì œì‹œí•˜ë¼.

        [OUTPUT FORMAT]
        - ì„œë¡ ì´ë‚˜ ê²°ë¡  ì—†ì´, ì™„ì„±ëœ ì˜ˆë¬¸ 3ê°œë§Œ í•œ ì¤„ì”© ì¶œë ¥í•˜ë¼.

        [ì˜ˆë¬¸ ì‹œì‘]
        """
        }

        # ë‚œì´ë„ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„ íƒ (ê¸°ë³¸ê°’: intermediate)
        prompt_template = prompt_templates.get(difficulty, prompt_templates["intermediate"])
        prompt = prompt_template.format(
            difficulty_level=difficulty,
            target_grade=target_grade,
            words_formatted=', '.join(words_formatted),
            target_grammar=target_grammar,
            kpop_context_text=kpop_context_text if kpop_context_text else "íŠ¹ë³„í•œ ê´€ì‹¬ì‚¬ ì—†ìŒ" # kpop_context_textê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ë¹„
            )
        # --- END: ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° ë¡œì§ ---

        
        response = self.llm.predict(prompt)
        sentences = response.strip().split('\n')
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•  ë°ì´í„° ìƒì„± (gradeë¥¼ levelë¡œ ì‚¬ìš©)
        save_data = {
            "level": target_grade,  # grade ê°’ì„ levelë¡œ ì‚¬ìš© 1-6
            "target_grammar": target_grammar,
            "kpop_references": kpop_references,
            "critique_summary": [{"sentence": s} for s in sentences]
        }
        
        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì¶”ê°€
        messages = [
            ("user", state['input_text']),
            ("assistant", "\n".join(sentences))
        ]
        
        return {
            "generated_sentences": sentences,
            "messages": messages,
            "sentence_data": save_data,
            "target_grade": target_grade  # stateì— grade ì •ë³´ ì¶”ê°€
        }
    
    def format_output(self, state: GraphState) -> GraphState:
        """ìµœì¢… ì¶œë ¥ í¬ë§·íŒ… ë° JSON ì €ì¥"""
        output = f"=== í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± ê²°ê³¼ ===\n"
        output += f"ë‚œì´ë„: {state['difficulty_level']}\n"
        
        # target_gradeê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if 'target_grade' in state:
            output += f"ë¬¸ë²• Grade: {state['target_grade']}\n"
        
        output += "\nì„ íƒëœ ë‹¨ì–´ (ìƒìœ„ 10ê°œ):\n"
        for i, doc in enumerate(state['vocabulary_docs'][:10], 1):
            word = doc.metadata.get('word', 'N/A')
            wordclass = doc.metadata.get('wordclass', 'N/A')
            guide = doc.metadata.get('guide', 'N/A')
            topik_level = doc.metadata.get('topik_level', 'N/A')
            output += f"{i}. {word} ({wordclass}) - {guide[:30]}... [TOPIK{topik_level}]\n"
        
        output += "\nì„ íƒëœ ë¬¸ë²• (ìƒìœ„ 10ê°œ, grade ë‚®ì€ ìˆœ):\n"
        for i, doc in enumerate(state['grammar_docs'][:10], 1):
            grammar = doc.metadata.get('grammar', 'N/A')
            grade = doc.metadata.get('grade', 'N/A')
            output += f"{i}. {grammar} (Grade: {grade})\n"
        
        output += "\nìƒì„±ëœ ì˜ˆë¬¸:\n"
        for i, sentence in enumerate(state['generated_sentences'], 1):
            output += f"{i}. {sentence}\n"
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (sentence_dataê°€ ìˆì„ ë•Œë§Œ)
        if 'sentence_data' in state and state['sentence_data']:
            saved_file = self._save_to_json(state['sentence_data'])
            output += f"\n ì˜ˆë¬¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_file}\n"
        
        return {"final_output": output}
    
    def _save_to_json(self, sentence_data: dict) -> str:
        out_dir = Path(SENTENCE_SAVE_DIR)
        out_dir.mkdir(parents=True, exist_ok=True)

        level = sentence_data.get("level", "grade1")
        title = sentence_data.get("title", "untitled")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        base = f"sentences_{level}_{title}_{timestamp}"
        safe_base = sanitize_filename(base)
        filepath = out_dir / f"{safe_base}.json"

        with open(filepath, "w", encoding="utf-8") as f:
            import json
            json.dump(sentence_data, f, ensure_ascii=False, indent=2)

        return str(filepath)

#Agent RAG êµ¬í˜„ ì¶”ê°€
class AgenticKoreanLearningNodes(KoreanLearningNodes):
    """
    Agentic RAG ë…¸ë“œ (ê¸°ì¡´ KoreanLearningNodes ìƒì†)
    ê¸°ì¡´ ê¸°ëŠ¥ì„ ëª¨ë‘ ìœ ì§€í•˜ë©´ì„œ Agentic ê¸°ëŠ¥ ì¶”ê°€
    """
    
    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        # ê¸°ì¡´ ì´ˆê¸°í™”
        super().__init__(vocabulary_retriever, grammar_retriever, kpop_retriever, llm)
        
        # Agentic ì—ì´ì „íŠ¸ ì¶”ê°€
        self.query_agent = QueryAnalysisAgent(llm)
        self.quality_agent = QualityCheckAgent(llm)
    
    def analyze_query_agent(self, state: GraphState) -> GraphState:
        """ì¿¼ë¦¬ ë¶„ì„ ì—ì´ì „íŠ¸ ë…¸ë“œ"""
        print("\nğŸ” [Agent] Query Analysis")
        analysis = self.query_agent.analyze(state['input_text'])
        
        print(f"   Difficulty: {analysis['difficulty']}")
        print(f"   Topic: {analysis['topic']}")
        
        return {
            "difficulty_level": analysis['difficulty'],
            "query_analysis": analysis
        }
    
    def retrieve_kpop_mixed(self, state: GraphState) -> GraphState:
        """
        K-pop ê²€ìƒ‰ ë…¸ë“œ (DB ì „ìš©)
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œë§Œ K-pop í•™ìŠµ ìë£Œ ê²€ìƒ‰
        """
        print("\nğŸµ [Agent] K-pop Retrieval (DB Only)")
        
        level = state['difficulty_level']
        query = state['input_text']
        
        # 1. ê¸°ì¡´ DBì—ì„œ ê²€ìƒ‰ (ìµœëŒ€ 5ê°œ)
        kpop_db_docs = self.kpop_retriever.invoke(query, level)
        kpop_db_docs = kpop_db_docs[:5]  # 5ê°œë¡œ ì œí•œ
        print(f"   DB ê²€ìƒ‰: {len(kpop_db_docs)}ê°œ")
        
        return {
            "kpop_docs": kpop_db_docs
        }
    
    
    """
    Updated check_quality_agent method for nodes.py
    Replace the existing method in AgenticKoreanLearningNodes class
    """

    def check_quality_agent(self, state: GraphState) -> GraphState:
        """í’ˆì§ˆ ê²€ì¦ ì—ì´ì „íŠ¸ ë…¸ë“œ"""
        print("\nâœ… [Agent] í’ˆì§ˆ ê²€ì¦")
        
        # ì¿¼ë¦¬ ë¶„ì„ì—ì„œ K-pop í•„ìš” ì—¬ë¶€ í™•ì¸
        query_analysis = state.get('query_analysis', {})
        needs_kpop = query_analysis.get('needs_kpop', False)
        
        result = self.quality_agent.check(
            vocab_count=len(state.get('vocabulary_docs', [])),
            grammar_count=len(state.get('grammar_docs', [])),
            kpop_db_count=len(state.get('kpop_docs', [])),
            needs_kpop=needs_kpop  # K-pop í•„ìš” ì—¬ë¶€ ì „ë‹¬
        )
        
        print(f"   ì–´íœ˜: {result['vocab_count']}ê°œ")
        print(f"   ë¬¸ë²•: {result['grammar_count']}ê°œ")
        if needs_kpop:
            print(f"   K-pop DB: {result['kpop_db_count']}ê°œ (í•„ìš”)")
        else:
            print(f"   K-pop DB: {result['kpop_db_count']}ê°œ (ë¶ˆí•„ìš”)")
        print(f"   ìƒíƒœ: {result['message']}")
        
        return {"quality_check": result}
    """
    Updated generate_sentences_with_kpop method for nodes.py
    Replace the existing method in AgenticKoreanLearningNodes class
    """

    def generate_sentences_with_kpop(self, state: GraphState) -> GraphState:
        """
        K-pop ì •ë³´ë¥¼ í™œìš©í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì¥ ìƒì„± (ì¡°ê±´ë¶€)
        K-pop ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ K-pop ë§¥ë½ í¬í•¨
        """
        print("\nâœï¸ [Agent] í•œêµ­ì–´ í•™ìŠµ ë¬¸ì¥ ìƒì„±")
        
        words_info = extract_words_from_docs(state['vocabulary_docs'])
        grammar_info = extract_grammar_with_grade(state['grammar_docs'])
        
        # K-pop ì •ë³´ í†µí•© (ìˆì„ ë•Œë§Œ)
        kpop_references = []
        kpop_context_text = ""
        has_kpop = False
        kpop_groups = []  # K-pop ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸
        kpop_songs = []   # K-pop ë…¸ë˜ ë¦¬ìŠ¤íŠ¸
        
        # DBì—ì„œ ê°€ì ¸ì˜¨ K-pop ë¬¸ì¥ë“¤
        kpop_db_docs = state.get('kpop_docs', [])
        if kpop_db_docs:
            has_kpop = True
            for doc in kpop_db_docs[:5]:
                sentence = doc.metadata.get('sentence', '')
                song = doc.metadata.get('song', '')
                group = doc.metadata.get('group', '')
                context = doc.metadata.get('context', '')
                
                if sentence:
                    kpop_references.append({
                        "sentence": sentence,
                        "song": song,
                        "group": group,
                        "context": context,
                        "source": "database"
                    })
                    kpop_context_text += f'- "{sentence}" ({song} - {group})\n'
                    
                    # ê·¸ë£¹ëª…ê³¼ ë…¸ë˜ ì œëª© ìˆ˜ì§‘
                    if group and group not in kpop_groups:
                        kpop_groups.append(group)
                    if song and song not in kpop_songs:
                        kpop_songs.append(song)
        
        # needs_kpop í™•ì¸ (ì¿¼ë¦¬ì— K-pop í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€)
        query_analysis = state.get('query_analysis', {})
        needs_kpop = query_analysis.get('needs_kpop', False)
        
        if has_kpop:
            print(f"   K-pop ì°¸ì¡° ë¬¸ì¥: {len(kpop_references)}ê°œ (DB)")
            if needs_kpop:
                print(f"   âš ï¸ K-pop ì¿¼ë¦¬ ê°ì§€: K-pop ë‚´ìš© í•„ìˆ˜ í¬í•¨")
        else:
            print(f"   K-pop ì°¸ì¡° ë¬¸ì¥: ì—†ìŒ (ì¼ë°˜ ì˜ˆë¬¸ ìƒì„±)")
        
        # ì–´íœ˜ í¬ë§·íŒ…
        words_formatted = []
        for word, wordclass in words_info[:5]:
            words_formatted.append(f"{word}({wordclass})")
        
        # ë¬¸ë²• ì„ íƒ
        if grammar_info:
            import random
            random_grammar_item = random.choice(grammar_info)
            target_grammar = random_grammar_item['grammar']
            target_grade = random_grammar_item['grade']
        else:
            target_grammar = "ê¸°ë³¸ ë¬¸ë²•"
            target_grade = 1
        
        # ë‚œì´ë„ë³„ ì„¤ëª…
        difficulty_guide = {
            "basic": "ì´ˆê¸‰ í•™ìŠµì (TOPIK 1-2ê¸‰): ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥, ê¸°ë³¸ ì‹œì œ ì‚¬ìš©",
            "intermediate": "ì¤‘ê¸‰ í•™ìŠµì (TOPIK 3-4ê¸‰): ë‹¤ì–‘í•œ ì—°ê²°ì–´ë¯¸, ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™” í‘œí˜„",
            "advanced": "ê³ ê¸‰ í•™ìŠµì (TOPIK 5-6ê¸‰): ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°, ê²©ì‹ì²´ë‚˜ ë¬¸ì–´ì²´ ê°€ëŠ¥"
        }
        
        difficulty = state['difficulty_level']
        
        # K-pop ìœ ë¬´ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if has_kpop and needs_kpop:
            # K-pop ì¿¼ë¦¬ì´ê³  ì°¸ì¡°ê°€ ìˆì„ ë•Œ - K-pop ë‚´ìš© í•„ìˆ˜
            kpop_groups_text = ', '.join(kpop_groups[:3]) if kpop_groups else ""
            kpop_songs_text = ', '.join(kpop_songs[:3]) if kpop_songs else ""
            
            kpop_instruction = f"""
    ã€K-pop ì°¸ì¡° ìë£Œ ({len(kpop_references)}ê°œ)ã€‘
    {kpop_context_text}
    
    ğŸµ K-pop ê·¸ë£¹: {kpop_groups_text}
    ğŸµ ë…¸ë˜ ì œëª©: {kpop_songs_text}

    **âš ï¸ K-pop í•„ìˆ˜ í¬í•¨ ê·œì¹™**:
    - ìœ„ì— ì œì‹œëœ K-pop ê·¸ë£¹ëª…(ì˜ˆ: {kpop_groups[0] if kpop_groups else 'BTS'})ì„ **ë°˜ë“œì‹œ** 3ê°œ ë¬¸ì¥ ëª¨ë‘ì— í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
    - K-pop ì°¸ì¡° ë¬¸ì¥ì˜ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”
    - ì˜ˆì‹œ: "{kpop_groups[0] if kpop_groups else 'BLACKPINK'}ì²˜ëŸ¼ ì¶¤ì¶”ê³  ì‹¶ì–´ìš”"
    - K-pop ê´€ë ¨ ë‚´ìš©ì´ ëª¨ë“  ë¬¸ì¥ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    """
            kpop_requirement = f"**í•„ìˆ˜**: K-pop ê´€ë ¨ ë‚´ìš©(ê·¸ë£¹ëª…, ë…¸ë˜ ë“±)ì´ 3ê°œ ë¬¸ì¥ ëª¨ë‘ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
        elif has_kpop and not needs_kpop:
            # K-pop ì°¸ì¡°ëŠ” ìˆì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹ ë•Œ
            kpop_instruction = f"""
    ã€K-pop ì°¸ì¡° ë¬¸ì¥ ({len(kpop_references)}ê°œ)ã€‘
    {kpop_context_text}

    **K-pop í™œìš© ê·œì¹™**:
    - ìœ„ì˜ K-pop ì°¸ì¡° ë¬¸ì¥ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - K-pop ì•„í‹°ìŠ¤íŠ¸, ë…¸ë˜, ë¬¸í™”ë¥¼ ì–¸ê¸‰í•˜ë©´ í•™ìŠµìì—ê²Œ ë” í¥ë¯¸ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """
            kpop_requirement = "K-pop ê´€ë ¨ ë‚´ìš©ì´ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ë˜ë©´ ì¢‹ì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹™ë‹ˆë‹¤"
        else:
            # K-pop ì°¸ì¡°ê°€ ì—†ì„ ë•Œ
            kpop_instruction = ""
            kpop_requirement = ""
        
        # ë¬¸ì¥ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ êµìœ¡ ë¬¸ì œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì¡°ê±´ì„ í™œìš©í•˜ì—¬ í•œêµ­ì–´ í•™ìŠµìš© ì˜ˆë¬¸ì„ **ì •í™•íˆ 3ê°œ** ìƒì„±í•´ì£¼ì„¸ìš”.

    ã€í•™ìŠµì ì •ë³´ã€‘
    - ìˆ˜ì¤€: {difficulty_guide.get(difficulty, 'ì¼ë°˜')}
    - ëª©í‘œ ë¬¸ë²•: {target_grammar} (ë“±ê¸‰ {target_grade})

    ã€í™œìš© ì–´íœ˜ã€‘
    {', '.join(words_formatted)}
    {kpop_instruction}
    ã€ë¬¸ì¥ ìƒì„± ê·œì¹™ã€‘
    1. **í•„ìˆ˜**: ì œì‹œëœ ì–´íœ˜ ì¤‘ ìµœì†Œ 3ê°œ ì´ìƒ í¬í•¨
    2. **í•„ìˆ˜**: ëª©í‘œ ë¬¸ë²• '{target_grammar}' ë°˜ë“œì‹œ ì‚¬ìš©
    3. ë¬¸ë²• ë“±ê¸‰ {target_grade}ì— ì í•©í•œ ë‚œì´ë„
    4. ì™¸êµ­ì¸ì´ í•œêµ­ì–´ë¥¼ ì‚¬ìš©ì‹œ ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í‘œí˜„
    5. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ 
    6. í•œêµ­ ë¬¸í™”ì ìœ¼ë¡œ ì ì ˆí•´ì•¼ í•œë‹¤
    {f'7. âœ… {kpop_requirement}' if kpop_requirement else ''}

    ã€ì¶œë ¥ í˜•ì‹ã€‘
    - ì •í™•íˆ 3ê°œ ë¬¸ì¥ë§Œ ì¶œë ¥
    - ë²ˆí˜¸ë‚˜ ì„¤ëª… ì—†ì´ ë¬¸ì¥ë§Œ ì¶œë ¥
    - ê° ë¬¸ì¥ì€ ìƒˆ ì¤„ì— ì‘ì„±

    ì˜ˆë¬¸ 3ê°œ:
    """
        
        response = self.llm.predict(prompt)
        sentences = response.strip().split('\n')
        sentences = [s.strip() for s in sentences if s.strip()][:3]  # ì •í™•íˆ 3ê°œ
        
        print(f"   ìƒì„± ì™„ë£Œ: {len(sentences)}ê°œ ë¬¸ì¥")
        
        # JSON ì €ì¥ ë°ì´í„°
        save_data = {
            "level": target_grade,
            "target_grammar": target_grammar,
            "kpop_references": kpop_references,  # ìˆì„ ë•Œë§Œ í¬í•¨
            "critique_summary": [{"sentence": s} for s in sentences]
        }
        
        messages = [
            ("user", state['input_text']),
            ("assistant", "\n".join(sentences))
        ]
        
        return {
            "generated_sentences": sentences,
            "messages": messages,
            "sentence_data": save_data,
            "target_grade": target_grade
        }


    def format_output_agentic(self, state: GraphState) -> GraphState:
        """ì¶œë ¥ í¬ë§·íŒ… (Agentic ë²„ì „ - í•œêµ­ì–´ êµìœ¡ ì¤‘ì‹¬)"""
        print("\nğŸ“„ [Agent] ìµœì¢… ì¶œë ¥ í¬ë§·íŒ…")
        
        difficulty_kr = {
            "basic": "ì´ˆê¸‰ (TOPIK 1-2ê¸‰)",
            "intermediate": "ì¤‘ê¸‰ (TOPIK 3-4ê¸‰)",
            "advanced": "ê³ ê¸‰ (TOPIK 5-6ê¸‰)"
        }
        
        output = f"=" * 80 + "\n"
        output += "ğŸ“ ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ í•™ìŠµ ë¬¸ì œ ìƒì„± ê²°ê³¼ (Agentic RAG)\n"
        output += "=" * 80 + "\n\n"
        
        # 1. í•™ìŠµì ì •ë³´
        difficulty = state.get('difficulty_level', 'basic')
        output += f"ã€í•™ìŠµì ìˆ˜ì¤€ã€‘\n"
        output += f"   ë‚œì´ë„: {difficulty_kr.get(difficulty, difficulty)}\n"
        
        if 'target_grade' in state:
            output += f"   ë¬¸ë²• ë“±ê¸‰: Grade {state['target_grade']}\n"
        
        # 2. ê²€ìƒ‰ëœ ì–´íœ˜
        vocab_docs = state.get('vocabulary_docs', [])
        if vocab_docs:
            output += f"\nã€ì„ íƒëœ í•™ìŠµ ì–´íœ˜ã€‘ (ìƒìœ„ 10ê°œ)\n"
            for i, doc in enumerate(vocab_docs[:10], 1):
                word = doc.metadata.get('word', 'N/A')
                wordclass = doc.metadata.get('wordclass', 'N/A')
                guide = doc.metadata.get('guide', 'N/A')
                topik_level = doc.metadata.get('topik_level', 'N/A')
                output += f"   {i}. {word} ({wordclass}) - {guide[:40]}... [TOPIK{topik_level}]\n"
        
        # 3. ê²€ìƒ‰ëœ ë¬¸ë²•
        grammar_docs = state.get('grammar_docs', [])
        if grammar_docs:
            output += f"\nã€ì„ íƒëœ í•™ìŠµ ë¬¸ë²•ã€‘ (ë“±ê¸‰ ë‚®ì€ ìˆœ)\n"
            for i, doc in enumerate(grammar_docs[:5], 1):
                grammar = doc.metadata.get('grammar', 'N/A')
                grade = doc.metadata.get('grade', 'N/A')
                output += f"   {i}. {grammar} (ë“±ê¸‰: {grade})\n"
        
        # 4. K-pop ì°¸ì¡° (ìˆì„ ë•Œë§Œ í‘œì‹œ)
        kpop_db_docs = state.get('kpop_docs', [])
        if kpop_db_docs:
            output += f"\nã€K-pop í•™ìŠµ ìë£Œã€‘ ë°ì´í„°ë² ì´ìŠ¤: {len(kpop_db_docs)}ê°œ\n"
            for i, doc in enumerate(kpop_db_docs[:5], 1):
                sentence = doc.metadata.get('sentence', 'N/A')
                song = doc.metadata.get('song', 'N/A')
                group = doc.metadata.get('group', 'N/A')
                output += f'   {i}. "{sentence}"\n'
                output += f'       â””â”€ {song} - {group}\n'
        
        # 5. ìƒì„±ëœ í•™ìŠµ ì˜ˆë¬¸
        sentences = state.get('generated_sentences', [])
        if sentences:
            kpop_label = " (K-pop ë§¥ë½ í¬í•¨)" if kpop_db_docs else ""
            output += f"\nã€ìƒì„±ëœ í•™ìŠµ ì˜ˆë¬¸ã€‘{kpop_label}\n"
            for i, sentence in enumerate(sentences, 1):
                output += f"   {i}. {sentence}\n"
        
        # 6. íŒŒì¼ ì €ì¥ ì •ë³´
        if 'sentence_data' in state and state['sentence_data']:
            saved_file = self._save_to_json(state['sentence_data'])
            output += f"\nğŸ’¾ í•™ìŠµ ìë£Œ ì €ì¥ ìœ„ì¹˜: {saved_file}\n"
        
        output += "\n" + "=" * 80 + "\n"
        
        return {"final_output": output}