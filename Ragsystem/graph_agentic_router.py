"""
ë¼ìš°í„° í†µí•© Agentic RAG ê·¸ë˜í”„
ì§€ëŠ¥í˜• ë¼ìš°íŒ… ê¸°ëŠ¥ì´ í¬í•¨ëœ LangGraph ì›Œí¬í”Œë¡œìš° (graph êµ¬í˜„)
ìˆ˜ì • ì™„ë£Œ
"""

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from typing import List
from Ragsystem.schema import GraphState
from Ragsystem.nodes_router_intergration import RouterIntegratedNodes  


class RouterAgenticGraph:
    """
    ë¼ìš°í„° í†µí•© Agentic RAG ê·¸ë˜í”„
    
    ì›Œí¬í”Œë¡œìš°:
    1. analyze_query: ì¿¼ë¦¬ ë¶„ì„ (ë‚œì´ë„, ì£¼ì œ, K-pop í•„ìš”ì„±)
    2. routing: ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½ (ì–´ë–¤ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€)
    3. retrieve_*: ì „ëµì— ë”°ë¥¸ ì„ íƒì  ê²€ìƒ‰
    4. check_quality: ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
    5. rerank (ì¡°ê±´ë¶€): í’ˆì§ˆ ë¶€ì¡± ì‹œ ì¬ê²€ìƒ‰
    6. generate: ì˜ˆë¬¸ ìƒì„±
    7. format_output: ìµœì¢… ì¶œë ¥
    """
    
    def __init__(self, vocabulary_retriever, grammar_retriever, kpop_retriever, llm=None):
        self.nodes = RouterIntegratedNodes(
            vocabulary_retriever,
            grammar_retriever,
            kpop_retriever,
            llm
        )
        self._build_graph()
    
    def _build_graph(self):
        """Build LangGraph workflow"""
        workflow = StateGraph(GraphState)
        
        #ë…¸ë“œ ì¶”ê°€
        
        # ì¿¼ë¦¬ ë¶„ì„
        workflow.add_node("analyze_query", self.nodes.analyze_query_agent)
        
        # ë¼ìš°íŒ…
        workflow.add_node("routing", self.nodes.routing_node)
        
        # ë¼ìš°íŒ… ê²°ê³¼ë¡œ ì–´ë–¤ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ í™œì„±í™”í•  ê²ƒì¸ê°€
        workflow.add_node("retrieve_vocabulary", self.nodes.retrieve_vocabulary_routed)
        workflow.add_node("retrieve_grammar", self.nodes.retrieve_grammar_routed)
        workflow.add_node("retrieve_kpop", self.nodes.retrieve_kpop_routed)
        
        # í’ˆì§ˆ ì²´í¬ ì—ì´ì „íŠ¸
        workflow.add_node("check_quality", self.nodes.check_quality_agent)
        
        # ì¬ê²€ìƒ‰ 
        workflow.add_node("rerank", self.nodes.rerank_node)
        
        # ìƒì„± (ë¬¸ì¥ ìƒì„± ì—†ì´ ì •ë³´ ì¶”ì¶œ í›„ ë¬¸ì œ ìƒì„±)
        workflow.add_node("generate", self.nodes.generate_question_directly)
        
        # output í¬ë§·
        workflow.add_node("format_output", self.nodes.format_output_agentic)
        

        # ì—£ì§€ ì—°ê²°
        # ì…ë ¥
        workflow.set_entry_point("analyze_query")
        
        # ë¶„ì„ -> ë¼ìš°íŒ…
        workflow.add_edge("analyze_query", "routing")
        
        # ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¼ ì¡°ê±´ë¶€ë¡œ ë¦¬íŠ¸ë¦¬ë²„ ì‹¤í–‰
        def route_to_retrievers(state: GraphState) -> List[str]:
            """
            ë¼ìš°íŒ… ê²°ì •ì— ë”°ë¼ í™œì„±í™”ëœ ë¦¬íŠ¸ë¦¬ë²„ë§Œ ë°˜í™˜
            ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            """
            decision = state.get("routing_decision")
            if not decision:
                # ê¸°ë³¸ê°’: vocabularyë§Œ ì‹¤í–‰
                return ["retrieve_vocabulary"]
            
            active_retrievers = []
            strategies = decision.strategies if hasattr(decision, 'strategies') else []
            
            for strategy in strategies:
                if strategy.retriever_type.value == "vocabulary":
                    active_retrievers.append("retrieve_vocabulary")
                elif strategy.retriever_type.value == "grammar":
                    active_retrievers.append("retrieve_grammar")
                elif strategy.retriever_type.value == "kpop":
                    active_retrievers.append("retrieve_kpop")
            
            # vocabularyëŠ” í•­ìƒ í¬í•¨ (ë¼ìš°í„°ì—ì„œ í•­ìƒ í™œì„±í™”)
            if "retrieve_vocabulary" not in active_retrievers:
                active_retrievers.insert(0, "retrieve_vocabulary")
            
            print(f"   ğŸ¯ í™œì„±í™”ëœ ë¦¬íŠ¸ë¦¬ë²„: {', '.join(active_retrievers)}")
            return active_retrievers
        
        # ì¡°ê±´ë¶€ ë³‘ë ¬ ì‹¤í–‰: ë¼ìš°íŒ… ê²°ì •ì— ë”°ë¼ í•„ìš”í•œ ë¦¬íŠ¸ë¦¬ë²„ë§Œ ì‹¤í–‰
        # LangGraph 0.6+ì—ì„œëŠ” ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ ì‹œ ìë™ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰ë¨
        workflow.add_conditional_edges(
            "routing",
            route_to_retrievers,  # ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ â†’ ë³‘ë ¬ ì‹¤í–‰
            {
                "retrieve_vocabulary": "retrieve_vocabulary",
                "retrieve_grammar": "retrieve_grammar",
                "retrieve_kpop": "retrieve_kpop"
            }
        )
        
        # ë¦¬íŠ¸ë¦¬ë²„ ì‹¤í–‰ í›„ ëª¨ë‘ check_qualityë¡œ ìˆ˜ë ´
        # LangGraphëŠ” ìë™ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì„ ìˆ˜ë ´ì‹œí‚´
        # ëª¨ë“  ë¦¬íŠ¸ë¦¬ë²„ ë…¸ë“œê°€ check_qualityë¡œ ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ ë³‘ë ¬ ì‹¤í–‰ í›„ ìˆ˜ë ´ ê°€ëŠ¥
        workflow.add_edge("retrieve_vocabulary", "check_quality")
        workflow.add_edge("retrieve_grammar", "check_quality")
        workflow.add_edge("retrieve_kpop", "check_quality")
        
        # í’ˆì§ˆ ì²´í¬ â†’ ì¡°ê±´ë¶€ ë¶„ê¸°
        def should_rerank(state: GraphState) -> str:
            """
            ì¬ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨ (1íšŒë§Œ)
            """
            quality = state.get('quality_check', {})
            sufficient = quality.get('sufficient', True)
            
            # ì¬ê²€ìƒ‰ 1íšŒë§Œ
            rerank_count = state.get('rerank_count', 0)
            
            if not sufficient and rerank_count < 1:  # 2íšŒì—ì„œ 1íšŒë¡œ ë³€ê²½
                print(f"   [ê²°ì •] ì¬ê²€ìƒ‰ ì‹¤í–‰ (1íšŒë§Œ)")
                return "rerank"
            else:
                if sufficient:
                    print("   [ê²°ì •] í’ˆì§ˆ ì¶©ì¡± â†’ ë¬¸ì¥ ìƒì„±")
                else:
                    print("   [ê²°ì •] ì¬ê²€ìƒ‰ ì™„ë£Œ â†’ ë¬¸ì¥ ìƒì„±")
                return "generate"
        
        workflow.add_conditional_edges(
            "check_quality",
            should_rerank,
            {
                "rerank": "rerank",
                "generate": "generate"
            }
        )
        
        # 5. ì¬ê²€ìƒ‰ â†’ ë‹¤ì‹œ í’ˆì§ˆ ì²´í¬
        workflow.add_edge("rerank", "check_quality")
        
        # ìƒì„±
        workflow.add_edge("generate", "format_output")
        
        # ê²°ê³¼, ë
        workflow.add_edge("format_output", END)
        

        # ì»´íŒŒì¼ë§
        memory = MemorySaver()
        self.workflow = workflow.compile(checkpointer=memory)
    
    def invoke(self, input_text: str, config=None):
        """ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        inputs = GraphState(
            input_text=input_text,
            difficulty_level="",
            vocabulary_docs=[],
            grammar_docs=[],
            kpop_docs=[],
            generated_sentences=[],
            final_output="",
            messages=[],
            query_analysis={},
            quality_check={},
            routing_decision=None,
            search_strategies=[],
            rerank_count=0,
            question_payload=None,
            sentence_data=None,
            target_grade=None
        )
        
        result = self.workflow.invoke(inputs, config)
        # final_outputê³¼ question_payload ëª¨ë‘ ë°˜í™˜
        return {
            'final_output': result.get('final_output', ''),
            'question_payload': result.get('question_payload')
        }
    
    def stream(self, input_text: str, config=None):
        """ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
        inputs = GraphState(
            input_text=input_text,
            difficulty_level="",
            vocabulary_docs=[],
            grammar_docs=[],
            kpop_docs=[],
            generated_sentences=[],
            final_output="",
            messages=[],
            query_analysis={},
            quality_check={},
            routing_decision=None,
            search_strategies=[],
            rerank_count=0,
            question_payload=None,
            sentence_data=None,
            target_grade=None
        )
        
        for output in self.workflow.stream(inputs, config):
            yield output
    
    def print_graph_structure(self):
        """ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š Agentic RAG ê·¸ë˜í”„ êµ¬ì¡°")
        print("="*80)
        print("\nğŸ”„ ì›Œí¬í”Œë¡œìš°:")
        print("\n1ï¸âƒ£  [Entry] analyze_query")
        print("   â””â”€> ì¿¼ë¦¬ ë¶„ì„ (ë‚œì´ë„, ì£¼ì œ, K-pop í•„ìš”ì„±, í•„í„° ì¡°ê±´)")
        print("   â””â”€> QueryAnalysisAgent ì‚¬ìš©")
        print("   â””â”€> ì¶œë ¥: query_analysis, difficulty_level")
        
        print("\n2ï¸âƒ£  [Node] routing")
        print("   â””â”€> ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½ (ì–´ë–¤ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€)")
        print("   â””â”€> IntelligentRouter ì‚¬ìš©")
        print("   â””â”€> ì¶œë ¥: routing_decision, search_strategies")
        
        print("\n3ï¸âƒ£  [Node] retrieve_vocabulary")
        print("   â””â”€> ì–´íœ˜ ê²€ìƒ‰ (í•­ìƒ í™œì„±í™”)")
        print("   â””â”€> TOPIKVocabularyRetriever ì‚¬ìš©")
        print("   â””â”€> ì¶œë ¥: vocabulary_docs (5ê°œ)")
        
        print("\n4ï¸âƒ£  [Node] retrieve_grammar")
        print("   â””â”€> ë¬¸ë²• ê²€ìƒ‰ (ë¬¸ë²• ê´€ë ¨ í‚¤ì›Œë“œ ìˆì„ ë•Œë§Œ í™œì„±í™”)")
        print("   â””â”€> GrammarRetriever ì‚¬ìš©")
        print("   â””â”€> ì¶œë ¥: grammar_docs (10ê°œ)")
        
        print("\n5ï¸âƒ£  [Node] retrieve_kpop")
        print("   â””â”€> K-pop ê²€ìƒ‰ (K-pop ê´€ë ¨ í‚¤ì›Œë“œ ìˆì„ ë•Œë§Œ í™œì„±í™”)")
        print("   â””â”€> KpopSentenceRetriever ì‚¬ìš© (DB ì „ìš©)")
        print("   â””â”€> ë™ì  í•„í„°ë§: ê·¸ë£¹, ë©¤ë²„, ì†Œì†ì‚¬, íŒ¬ë¤, ì»¨ì…‰, ë°ë·” ì—°ë„, ê·¸ë£¹ íƒ€ì…")
        print("   â””â”€> ì¶œë ¥: kpop_docs (5ê°œ)")
        
        print("\n6ï¸âƒ£  [Node] check_quality")
        print("   â””â”€> ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦")
        print("   â””â”€> QualityCheckAgent ì‚¬ìš©")
        print("   â””â”€> ê¸°ì¤€: ì–´íœ˜ 3ê°œ, ë¬¸ë²• 1ê°œ, K-pop 3ê°œ (í•„ìš”ì‹œ)")
        print("   â””â”€> ì¶œë ¥: quality_check")
        
        print("\n7ï¸âƒ£  [Conditional] should_rerank")
        print("   â”œâ”€> í’ˆì§ˆ ì¶©ì¡± â†’ generate")
        print("   â””â”€> í’ˆì§ˆ ë¶€ì¡± + rerank_count < 1 â†’ rerank")
        
        print("\n8ï¸âƒ£  [Node] rerank (ì¡°ê±´ë¶€)")
        print("   â””â”€> ì¬ê²€ìƒ‰ ì‹¤í–‰ (ìµœëŒ€ 1íšŒ)")
        print("   â””â”€> ë¶€ì¡±í•œ ë¦¬íŠ¸ë¦¬ë²„ë§Œ ì¬ê²€ìƒ‰")
        print("   â””â”€> ì¶œë ¥: vocabulary_docs, grammar_docs, kpop_docs ì—…ë°ì´íŠ¸")
        print("   â””â”€> rerank_count ì¦ê°€")
        print("   â””â”€> â†’ check_qualityë¡œ ëŒì•„ê°")
        
        print("\n9ï¸âƒ£  [Node] generate")
        print("   â””â”€> ë¬¸ì œ ìƒì„±ìš© payload êµ¬ì„±")
        print("   â””â”€> ë¬¸ì¥ ìƒì„± ì—†ì´ ì •ë³´ë§Œ ì¶”ì¶œ")
        print("   â””â”€> ì¶œë ¥: question_payload, sentence_data")
        
        print("\nğŸ”Ÿ [Node] format_output")
        print("   â””â”€> ìµœì¢… ì¶œë ¥ í¬ë§·íŒ…")
        print("   â””â”€> ì¶œë ¥: final_output")
        
        print("\nâ¹ï¸  [End] END")
        print("   â””â”€> ìµœì¢… ê²°ê³¼ ë°˜í™˜")
        
        print("\n" + "="*80)
        print("ğŸ“‹ ë…¸ë“œ ì—°ê²° êµ¬ì¡°:")
        print("="*80)
        print("""
Entry
  â”‚
  â–¼
analyze_query
  â”‚
  â–¼
routing
  â”‚
  â”œâ”€[í™œì„±í™”ëœ ë¦¬íŠ¸ë¦¬ë²„ë§Œ ë³‘ë ¬ ì‹¤í–‰]â”€â”
  â”‚                                  â”‚
  â”œâ”€> retrieve_vocabulary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”œâ”€> retrieve_grammar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ (ë³‘ë ¬)
  â””â”€> retrieve_kpop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼ (ëª¨ë“  ë¦¬íŠ¸ë¦¬ë²„ ì™„ë£Œ í›„ ìˆ˜ë ´)
check_quality
  â”‚
  â”œâ”€[sufficient]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        â”‚
  â””â”€[insufficient]        â”‚
     â”‚                     â”‚
     â–¼                     â”‚
  rerank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                     â”‚
     â””â”€> check_quality â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         generate
              â”‚
              â–¼
      format_output
              â”‚
              â–¼
            END
        """)
        print("="*80)
        print("\nğŸ’¡ ì£¼ìš” íŠ¹ì§•:")
        print("   â€¢ Vocabulary ë¦¬íŠ¸ë¦¬ë²„: í•­ìƒ í™œì„±í™”")
        print("   â€¢ Grammar ë¦¬íŠ¸ë¦¬ë²„: ë¬¸ë²• ê´€ë ¨ í‚¤ì›Œë“œ ìˆì„ ë•Œë§Œ í™œì„±í™”")
        print("   â€¢ K-pop ë¦¬íŠ¸ë¦¬ë²„: K-pop ê´€ë ¨ í‚¤ì›Œë“œ ìˆì„ ë•Œë§Œ í™œì„±í™”")
        print("   â€¢ ë³‘ë ¬ ì‹¤í–‰: í™œì„±í™”ëœ ë¦¬íŠ¸ë¦¬ë²„ëŠ” ë™ì‹œì— ì‹¤í–‰ (ì„±ëŠ¥ í–¥ìƒ)")
        print("   â€¢ ì¬ê²€ìƒ‰: ìµœëŒ€ 1íšŒë§Œ ì‹¤í–‰ (ë¬´í•œ ë£¨í”„ ë°©ì§€)")
        print("   â€¢ ì¿¼ë¦¬ë³„ ì¤‘ë³µ ë°©ì§€: ë‹¨ì–´/ë¬¸ë²• ìºì‹œë¡œ ì´ì „ ê²°ê³¼ ì œì™¸")
        print("\nâš¡ ì„±ëŠ¥:")
        print("   â€¢ ì„ í˜• ì‹¤í–‰: 3ê°œ ë¦¬íŠ¸ë¦¬ë²„ = 3ì´ˆ")
        print("   â€¢ ë³‘ë ¬ ì‹¤í–‰: 3ê°œ ë¦¬íŠ¸ë¦¬ë²„ = 1ì´ˆ (ê°€ì¥ ê¸´ ê²ƒ ê¸°ì¤€)")
        print("="*80 + "\n")

