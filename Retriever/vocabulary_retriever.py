# =====================================
# vocabulary_retriever.py
# =====================================
"""
TOPIK ë‹¨ì–´ Retriever
"""
import os
from pydoc import doc
import pandas as pd
from typing import List, Dict
from langchain.schema import Document
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.retrievers import EnsembleRetriever, BM25Retriever


class TOPIKVocabularyRetriever:
    """TOPIK ë‹¨ì–´ CSV íŒŒì¼ ê¸°ë°˜ Retriever"""
    
    def __init__(self, csv_paths: Dict[str, List[str]]):
        self.csv_paths = csv_paths
        self.vocabulary_data = {}
        self.retrievers = {}
        self._load_vocabulary()
        self._create_retrievers()
    
    
    def _load_vocabulary(self):
        """CSV íŒŒì¼ë“¤ì„ ë ˆë²¨ë³„ë¡œ ë¡œë“œ"""
        for level, paths in self.csv_paths.items():
            level_documents = []
            for path in paths:
                try:
                    df = pd.read_csv(path, encoding='utf-8')
                    for _, row in df.iterrows():
                        # CSV ì»¬ëŸ¼: Number, Level, Vocabulary, Wordclass, Guide
                        vocabulary = row.get('Vocabulary', '')
                        wordclass = row.get('Wordclass', '')
                        guide = row.get('Guide', '')
                        topik_level = row.get('Level', '')
                        
                        doc_content = f"ë‹¨ì–´: {vocabulary}\n"
                        doc_content += f"í’ˆì‚¬: {wordclass}\n"
                        doc_content += f"ì„¤ëª…: {guide}\n"
                        doc_content += f"TOPIK ë ˆë²¨: {topik_level}"
                        
                        doc = Document(
                            page_content=doc_content,
                            metadata={
                                'difficulty_level': level,
                                'source': path,
                                'word': vocabulary,
                                'wordclass': wordclass,
                                'guide': guide,
                                'topik_level': topik_level,
                                'file_name': path.split('/')[-1].replace('.csv', '')
                            }
                        )
                        level_documents.append(doc)
                except Exception as e:
                    print(f"Error loading {path}: {e}")
            
            self.vocabulary_data[level] = level_documents
    
    def _create_retrievers(self):
        """ë ˆë²¨ë³„ retriever ìƒì„±"""
        embeddings = OpenAIEmbeddings()
        
        for level, documents in self.vocabulary_data.items():
            if documents:
                # Vector Store Retriever
                vectorstore = FAISS.from_documents(documents, embeddings)
                vector_retriever = vectorstore.as_retriever(
                    search_kwargs={"k": 10}
                )
                
                # BM25 Retriever
                bm25_retriever = BM25Retriever.from_documents(documents)
                bm25_retriever.k = 10
                
                # Ensemble Retriever
                ensemble_retriever = EnsembleRetriever(
                    retrievers=[vector_retriever, bm25_retriever],
                    weights=[0.5, 0.5]
                )
                
                self.retrievers[level] = ensemble_retriever
    
    def invoke(self, query: str, level: str) -> List[Document]:
        """ë‚œì´ë„ì— ë”°ë¥¸ ë‹¨ì–´ ê²€ìƒ‰"""
        if level in self.retrievers:
            return self.retrievers[level].get_relevant_documents(query)
        return []


def _load_vocabulary(self):
    """CSV íŒŒì¼ë“¤ì„ ë ˆë²¨ë³„ë¡œ ë¡œë“œ"""
    for level, paths in self.csv_paths.items():
        level_documents = []
        print(f"ğŸ“– [{level}] ì–´íœ˜ ë¡œë”© ì¤‘...")
        
        for path in paths:
            try:
                if not os.path.exists(path):
                    print(f"   âŒ íŒŒì¼ ì—†ìŒ: {path}")
                    continue
                    
                df = pd.read_csv(path, encoding='utf-8')
                print(f"   âœ… {path}: {len(df)}ê°œ ë‹¨ì–´")
                
                for _, row in df.iterrows():
                    # ... (ê¸°ì¡´ ì½”ë“œ)
                    level_documents.append(doc)
                    
            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜ ({path}): {e}")
        
        print(f"   ì´ {len(level_documents)}ê°œ ë¬¸ì„œ ìƒì„±")
        self.vocabulary_data[level] = level_documents